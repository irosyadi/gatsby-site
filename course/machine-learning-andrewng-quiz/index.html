<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0"/><style data-href="/styles.298790c01e4cb45e1978.css" id="gatsby-global-css">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::-ms-input-placeholder,textarea::-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}</style><meta name="generator" content="Gatsby 2.27.0"/><style type="text/css">
    .toc-header.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .toc-header.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .toc-header svg,
    h2 .toc-header svg,
    h3 .toc-header svg,
    h4 .toc-header svg,
    h5 .toc-header svg,
    h6 .toc-header svg {
      visibility: hidden;
    }
    h1:hover .toc-header svg,
    h2:hover .toc-header svg,
    h3:hover .toc-header svg,
    h4:hover .toc-header svg,
    h5:hover .toc-header svg,
    h6:hover .toc-header svg,
    h1 .toc-header:focus svg,
    h2 .toc-header:focus svg,
    h3 .toc-header:focus svg,
    h4 .toc-header:focus svg,
    h5 .toc-header:focus svg,
    h6 .toc-header:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect" href="https://www.google-analytics.com"/><link rel="dns-prefetch" href="https://www.google-analytics.com"/><link rel="icon" href="/favicon-32x32-dcbe031e7de951bb1a507e8da72e1d1a.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#3F4145"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512-dcbe031e7de951bb1a507e8da72e1d1a.png"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><title data-react-helmet="true">Machine Learning Andrew Ng Quizes | irosyadi</title><meta data-react-helmet="true" name="description" content="Machine Learning Andrew Ng Quizes Week 1 Introduction A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as meas‚Ä¶"/><meta data-react-helmet="true" property="og:title" content="Machine Learning Andrew Ng Quizes"/><meta data-react-helmet="true" property="og:description" content="Machine Learning Andrew Ng Quizes Week 1 Introduction A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as meas‚Ä¶"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="irosyadi"/><meta data-react-helmet="true" name="twitter:title" content="Machine Learning Andrew Ng Quizes"/><meta data-react-helmet="true" name="twitter:description" content="Machine Learning Andrew Ng Quizes Week 1 Introduction A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as meas‚Ä¶"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link as="script" rel="preload" href="/webpack-runtime-a3cc835446b553ef5321.js"/><link as="script" rel="preload" href="/styles-f2c1808a00cfb3adf39e.js"/><link as="script" rel="preload" href="/framework-b049b847da93b37c0f49.js"/><link as="script" rel="preload" href="/dc6a8720040df98778fe970bf6c000a41750d3ae-899cddfdf609eb8bc0c3.js"/><link as="script" rel="preload" href="/app-f6ca4d5f718b892ec182.js"/><link as="script" rel="preload" href="/d7eeaac4-dcbe97e7a5aa158c9d08.js"/><link as="script" rel="preload" href="/5e2a4920-da90abce4a08c86a094c.js"/><link as="script" rel="preload" href="/1bfc9850-409296e666dade882413.js"/><link as="script" rel="preload" href="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-30f26f77b6c7c05712d1.js"/><link as="script" rel="preload" href="/7a297f752dcfe258c0b0106d89edb3a916af916e-37098fdb13001ec95411.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-f9a7f3940ce358b5d109.js"/><link as="fetch" rel="preload" href="/page-data/course/machine-learning-andrewng-quiz/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1081905842.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/63159454.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><noscript><style data-emotion-css="1vyo7ug">.css-1vyo7ug{position:fixed;bottom:0;left:0;margin-left:0.5rem;margin-bottom:0.5rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-size:0.875rem;font-weight:700;padding-left:1rem;padding-right:1rem;padding-top:0.75rem;padding-bottom:0.75rem;background-color:#86a8e7;z-index:9999;}</style><div class="css-1vyo7ug"><style data-emotion-css="5x4yj0">.css-5x4yj0{fill:currentColor;width:1.5rem;height:1.5rem;margin-right:0.5rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 192 512" class="css-5x4yj0" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 424.229h20V279.771H20c-11.046 0-20-8.954-20-20V212c0-11.046 8.954-20 20-20h112c11.046 0 20 8.954 20 20v212.229h20c11.046 0 20 8.954 20 20V492c0 11.046-8.954 20-20 20H20c-11.046 0-20-8.954-20-20v-47.771c0-11.046 8.954-20 20-20zM96 0C56.235 0 24 32.235 24 72s32.235 72 72 72 72-32.235 72-72S135.764 0 96 0z"></path></svg><style data-emotion-css="1f2k2gl">.css-1f2k2gl{margin-left:0.5rem;}</style><div class="css-1f2k2gl">Please enable JavaScript to use this site.</div></div></noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="f6s0ma">.css-f6s0ma{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><style data-emotion-css="acifd">.css-acifd{min-height:100vh;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#333333;}</style><div class="css-acifd e60ayux0"><style data-emotion-css="8ezs2g">.css-8ezs2g{min-height:calc(100vh - 100px);}</style><div class="css-8ezs2g"><style data-emotion-css="1yxw6gp">.css-1yxw6gp{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );}</style><div class="css-1yxw6gp"><style data-emotion-css="1mqm4zt">.css-1mqm4zt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;max-width:1280px;margin-left:auto;margin-right:auto;padding:1.25rem;}</style><nav class="css-1mqm4zt e1czdvww0"><style data-emotion-css="1usmgm5">.css-1usmgm5{font-size:1.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));font-weight:700;}</style><a class="css-1usmgm5" href="/">irosyadi</a><a aria-label="search page" href="/search"><style data-emotion-css="47445j">.css-47445j{--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));margin-top:auto;margin-bottom:auto;width:2rem;height:2rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="aod07n">.css-aod07n{background:linear-gradient( 90deg,#7f7fd5,#86a8e7 );position:fixed;width:100%;box-shadow:0 1px 3px 0 rgba(0,0,0,0.1),0 1px 2px 0 rgba(0,0,0,0.06);z-index:100;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);top:-100px;}</style><div class="css-aod07n"><nav class="css-1mqm4zt e1czdvww0"><a class="css-1usmgm5" href="/">irosyadi</a><a aria-label="search page" href="/search"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-47445j" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M909.6 854.5L649.9 594.8C690.2 542.7 712 479 712 412c0-80.2-31.3-155.4-87.9-212.1-56.6-56.7-132-87.9-212.1-87.9s-155.5 31.3-212.1 87.9C143.2 256.5 112 331.8 112 412c0 80.1 31.3 155.5 87.9 212.1C256.5 680.8 331.8 712 412 712c67 0 130.6-21.8 182.7-62l259.7 259.6a8.2 8.2 0 0 0 11.6 0l43.6-43.5a8.2 8.2 0 0 0 0-11.6zM570.4 570.4C528 612.7 471.8 636 412 636s-116-23.3-158.4-65.6C211.3 528 188 471.8 188 412s23.3-116.1 65.6-158.4C296 211.3 352.2 188 412 188s116.1 23.2 158.4 65.6S636 352.2 636 412s-23.3 116.1-65.6 158.4z"></path></svg></a></nav></div><style data-emotion-css="w27u98">.css-w27u98{margin-top:1rem;padding-left:1rem;padding-right:1rem;}</style><div class="blog-post-container css-w27u98"><div class="blog-post"><style data-emotion-css="1bdwg0l">.css-1bdwg0l{width:100%;max-width:768px;margin-left:auto;margin-right:auto;}</style><div class="css-1bdwg0l eyldt480"><style data-emotion-css="1abxlfd">.css-1abxlfd{font-size:2.25rem;font-weight:700;margin-bottom:1rem;}@media (min-width:768px){.css-1abxlfd{font-size:3rem;}}</style><h1 class="blog-title css-1abxlfd">Machine Learning Andrew Ng Quizes</h1><style data-emotion-css="cpn9zx">.css-cpn9zx{font-size:1rem;margin-bottom:1rem;}</style><h2 class="blog-date css-cpn9zx">06 - 01 - 2021</h2><style data-emotion-css="cet0rr">.css-cet0rr{margin-bottom:0.5rem;}</style><div class="blog-tags css-cet0rr"><style data-emotion-css="1ak4bcm">.css-1ak4bcm{white-space:nowrap;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);font-size:1rem;font-weight:700;border-radius:9999px;margin-right:0.5rem;margin-top:0.25rem;margin-bottom:0.25rem;padding-top:0.25rem;padding-bottom:0.25rem;padding-left:0.75rem;padding-right:0.75rem;background-color:#edf2f7;color:#3737B9;}</style><button class="css-1ak4bcm">quiz</button><button class="css-1ak4bcm">machine learning</button></div><style data-emotion-css="1l4w6pd">.css-1l4w6pd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}</style><div class="css-1l4w6pd"><style data-emotion-css="yapsbb">.css-yapsbb{border-radius:9999px;width:100%;height:1px;--bg-opacity:1;background-color:rgba(247,250,252,var(--bg-opacity));background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="css-yapsbb"></div></div></div><div class="blog-content"><style data-emotion-css="19vk1qv">.css-19vk1qv{-webkit-scrollbar-width:thin;-moz-scrollbar-width:thin;-ms-scrollbar-width:thin;scrollbar-width:thin;-webkit-scrollbar-color:gray transparent;-moz-scrollbar-color:gray transparent;-ms-scrollbar-color:gray transparent;scrollbar-color:gray transparent;display:none;}.css-19vk1qv::-webkit-scrollbar{width:4px;}.css-19vk1qv::-webkit-scrollbar-track{background-color:transparent;}.css-19vk1qv::-webkit-scrollbar-thumb{border-radius:9999px;background-color:gray;}.css-19vk1qv::-webkit-scrollbar-button{width:0;height:0;}@media screen and (min-width:1280px){.css-19vk1qv{float:right;position:-webkit-sticky;position:sticky;top:100px;width:calc((100vw - 720px) / 2 - 80px);max-width:250px;margin-right:1rem;overflow:auto;word-break:break-word;max-height:calc(100vh - 200px);fontsize:1rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;border-left-width:4px;border-image:linear-gradient( 180deg,#7f7fd5,#86a8e7,#91eac9 );border-image-slice:1;}}</style><div class="css-19vk1qv"><style data-emotion-css="13af3fo">.css-13af3fo{margin-left:1rem;margin-right:1rem;}</style><div class="css-13af3fo"><style data-emotion-css="17i5xbf">.css-17i5xbf{font-weight:700;margin-bottom:0.5rem;font-size:1.125rem;--text-opacity:1;color:rgba(74,85,104,var(--text-opacity));}</style><h3 class="css-17i5xbf">TOC</h3><style data-emotion-css="1me4zjn">.css-1me4zjn ul{margin-left:0.5rem;}.css-1me4zjn ul > li a:hover{color:#555555;}.css-1me4zjn ul > li a{-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);--text-opacity:1;color:rgba(160,174,192,var(--text-opacity));font-size:0.875rem;}.css-1me4zjn ul > li a[href=""]{font-size:0.95rem;color:#555555;}</style><div class="css-1me4zjn"><ul>
<li>
<p><a href="/course/machine-learning-andrewng-quiz/#machine-learning-andrew-ng-quizes">Machine Learning Andrew Ng Quizes</a></p>
<ul>
<li>
<p><a href="/course/machine-learning-andrewng-quiz/#week-1">Week 1</a></p>
<ul>
<li><a href="/course/machine-learning-andrewng-quiz/#introduction">Introduction</a></li>
<li><a href="/course/machine-learning-andrewng-quiz/#linear-regression-with-one-variable-">Linear Regression with One Variable :</a></li>
</ul>
</li>
<li>
<p><a href="/course/machine-learning-andrewng-quiz/#week-4">Week 4</a></p>
<ul>
<li><a href="/course/machine-learning-andrewng-quiz/#logistic-regression-">Logistic Regression :</a></li>
<li><a href="/course/machine-learning-andrewng-quiz/#regularization">Regularization</a></li>
</ul>
</li>
<li>
<p><a href="/course/machine-learning-andrewng-quiz/#week-5">Week 5</a></p>
<ul>
<li><a href="/course/machine-learning-andrewng-quiz/#neural-networks---representation-">Neural Networks - Representation :</a></li>
<li><a href="/course/machine-learning-andrewng-quiz/#neural-networks-learning-">Neural Networks: Learning :</a></li>
</ul>
</li>
<li>
<p><a href="/course/machine-learning-andrewng-quiz/#week-6">Week 6</a></p>
<ul>
<li><a href="/course/machine-learning-andrewng-quiz/#advice-for-applying-machine-learning-">Advice for Applying Machine Learning :</a></li>
</ul>
</li>
<li><a href="/course/machine-learning-andrewng-quiz/#links">Links</a></li>
</ul>
</li>
</ul></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="1umqqmp">.css-1umqqmp{font-size:1rem;word-break:break-word;}.css-1umqqmp h1 > a > svg,.css-1umqqmp h2 > a > svg,.css-1umqqmp h3 > a > svg,.css-1umqqmp h4 > a > svg,.css-1umqqmp h5 > a > svg,.css-1umqqmp h6 > a > svg{fill:#000;}.css-1umqqmp h1,.css-1umqqmp h2{font-size:1.25rem;font-weight:600;margin-top:1.5rem;margin-bottom:1.5rem;}.css-1umqqmp h3,.css-1umqqmp h4,.css-1umqqmp h5,.css-1umqqmp h6{font-size:1.125rem;margin-top:1.5rem;margin-bottom:1.5rem;font-weight:600;}@media (min-width:640px){.css-1umqqmp h1,.css-1umqqmp h2{font-size:1.5rem;}.css-1umqqmp h3,.css-1umqqmp h4,.css-1umqqmp h5,.css-1umqqmp h6{font-size:1.25rem;}}.css-1umqqmp a{color:#3737B9;}.css-1umqqmp a:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-1umqqmp p{margin:0.3rem;margin-top:0.75rem;margin-bottom:0.75rem;}.css-1umqqmp ul,.css-1umqqmp ol{margin:0.3rem;margin-left:2rem;}.css-1umqqmp li > p,.css-1umqqmp li > ul,.css-1umqqmp li > ol{margin-bottom:0;}.css-1umqqmp ol{list-style-type:decimal;}.css-1umqqmp ul{list-style-type:disc;}.css-1umqqmp blockquote{padding:0.5rem;background-color:#eee;margin:0.3rem;margin-top:0.5rem;margin-bottom:0.5rem;border-left-width:4px;border-color:#86a8e7;}.css-1umqqmp blockquote > p{margin:0.5rem;}.css-1umqqmp blockquote > h1,.css-1umqqmp blockquote > h2,.css-1umqqmp blockquote > h3,.css-1umqqmp blockquote > h4,.css-1umqqmp blockquote > h5{margin-top:0.5rem;margin-bottom:0.5rem;}.css-1umqqmp td,.css-1umqqmp th{padding-left:0.5rem;padding-right:0.5rem;padding-top:0.25rem;padding-bottom:0.25rem;border-width:1px;border-color:#86a8e7;}.css-1umqqmp tr:nth-of-type(even){background-color:#eee;}.css-1umqqmp th{background-color:#eee;}.css-1umqqmp table{margin-bottom:1.5rem;}.css-1umqqmp p > code,.css-1umqqmp li > code{padding-top:0.1rem;padding-bottom:0.1rem;padding-right:0.25rem;padding-left:0.25rem;border-radius:0.25rem;color:#3737B9;background-color:#eee;white-space:pre-line;}.css-1umqqmp pre.grvsc-container{margin-top:24px;margin-bottom:24px;}.css-1umqqmp hr{margin-top:24px;margin-bottom:24px;height:2px;border:none;background:linear-gradient( 270deg,#7f7fd5,#86a8e7,#91eac9 );}</style><div class="markdown css-1umqqmp"><h1 id="machine-learning-andrew-ng-quizes" style="position:relative;"><a href="#machine-learning-andrew-ng-quizes" aria-label="machine learning andrew ng quizes permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning Andrew Ng Quizes</h1>
<h2 id="week-1" style="position:relative;"><a href="#week-1" aria-label="week 1 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Week 1</h2>
<h3 id="introduction" style="position:relative;"><a href="#introduction" aria-label="introduction permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h3>
<ol>
<li>
<p>A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as measured by P, improves with experience E. Suppose we feed a learning algorithm a lot of historical weather data, and have it learn to predict weather. <strong>What would be a reasonable choice for P?</strong> </p>
<ul>
<li>üóπ The probability of it correctly predicting a future date‚Äôs weather.</li>
<li>‚òê The weather prediction task.</li>
<li>‚òê The process of the algorithm examining a large amount of historical weather data.</li>
<li>‚òê None of these.</li>
</ul>
</li>
<li>
<p>A computer program is said to learn from experience E with respect to some task T and some performance measure P if its performance on T, as measured by P, improves with experience E. Suppose we feed a learning algorithm a lot of historical weather data, and have it learn to predict weather. In this setting, <strong>what is T?</strong></p>
<ul>
<li>üóπ The weather prediction task.</li>
<li>‚òê None of these.</li>
<li>‚òê The probability of it correctly predicting a future date‚Äôs weather.</li>
<li>‚òê The process of the algorithm examining a large amount of historical weather data.</li>
</ul>
</li>
<li>
<p>Suppose you are working on weather prediction, and use a learning algorithm to predict tomorrow‚Äôs temperature (in degrees Centigrade/Fahrenheit).<br>
Would you treat this as a classification or a regression problem?</p>
<ul>
<li>üóπ Regression</li>
<li>‚òê Classification</li>
</ul>
</li>
<li>
<p>Suppose you are working on weather prediction, and your weather station makes one of three predictions for each day‚Äôs weather: <strong>Sunny, Cloudy or Rainy</strong>. You‚Äôd like to use a learning algorithm to predict tomorrow‚Äôs weather.<br>
Would you treat this as a classification or a regression problem?</p>
<ul>
<li>‚òê Regression</li>
<li>üóπ Classification</li>
</ul>
</li>
<li>
<p>Suppose you are working on stock market prediction, and you would like to predict the <strong>price of a particular stock tomorrow (measured in dollars)</strong>. You want to use a learning algorithm for this.<br>
Would you treat this as a classification or a regression problem?</p>
<ul>
<li>üóπ Regression</li>
<li>‚òê Classification</li>
</ul>
</li>
<li>
<p>Suppose you are working on stock market prediction. You would like to predict <strong>whether or not a certain company will declare bankruptcy within the next 7 days</strong> (by training on data of similar companies that had previously been at risk of bankruptcy).<br>
Would you treat this as a classification or a regression problem?</p>
<ul>
<li>Regression</li>
<li>üóπ Classification</li>
</ul>
</li>
<li>
<p>Suppose you are working on stock market prediction, Typically tens of millions of shares of Microsoft stock are traded (i.e., bought/sold) each day. You would like to predict the number of Microsoft shares that will be traded tomorrow.<br>
Would you treat this as a classification or a regression problem?</p>
<ul>
<li>üóπ Regression</li>
<li>Classification</li>
</ul>
</li>
<li>
<p>Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case, assume some appropriate dataset is available for your algorithm to learn from.  </p>
<ul>
<li>üóπ Given historical data of children‚Äôs ages and heights, predict children‚Äôs height as a function of their age.</li>
<li>üóπ Given 50 articles written by male authors, and 50 articles written by female authors, learn to predict the gender of a new manuscript‚Äôs author (when the identity of this author is unknown).</li>
<li>Take a collection of 1000 essays written on the US Economy, and find a way to automatically group these essays into a small number of groups of essays that are somehow ‚Äúsimilar‚Äù or ‚Äúrelated‚Äù.</li>
<li>Examine a large collection of emails that are known to be spam email, to discover if there are sub-types of spam mail.</li>
</ul>
</li>
<li>
<p>Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case, assume some appropriate dataset is available for your algorithm to learn from.  </p>
<ul>
<li>‚òê Given data on how 1000 medical patients respond to an experimental drug (such as effectiveness of the treatment, side effects, etc.), discover whether there are different categories or ‚Äútypes‚Äù of patients in terms of how they respond to the drug, and if so what these categories are.</li>
<li>‚òê Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments.</li>
<li>üóπ Have a computer examine an audio clip of a piece of music, and classify whether or not there are vocals (i.e., a human voice singing) in that audio clip, or if it is a clip of only musical instruments (and no vocals).</li>
<li>üóπ Given genetic (DNA) data from a person, predict the odds of him/her developing diabetes over the next 10 years.</li>
</ul>
</li>
<li>
<p>Some of the problems below are best addressed using a supervised learning algorithm, and the others with an unsupervised learning algorithm. Which of the following would you apply supervised learning to? (Select all that apply.) In each case, assume some appropriate dataset is available for your algorithm to learn from.</p>
<ul>
<li>‚òê Take a collection of 1000 essays written on the US Economy, and find a way to automatically group these essays into a small number of groups of essays that are somehow ‚Äúsimilar‚Äù or ‚Äúrelated‚Äù.</li>
<li>üóπ Given genetic (DNA) data from a person, predict the odds of him/her developing diabetes over the next 10 years.</li>
<li>‚òê Examine a large collection of emails that are known to be spam email, to discover if there are sub-types of spam mail.</li>
<li>üóπ  Examine the statistics of two football teams, and predict which team will win tomorrow‚Äôs match (given historical data of teams‚Äô wins/losses to learn from).</li>
</ul>
</li>
<li>
<p>Which of these is a reasonable definition of machine learning?  </p>
<ul>
<li>‚òê Machine learning is the science of programming computers.</li>
<li>‚òê Machine learning learns from labeled data.</li>
<li>‚òê Machine learning is the field of allowing robots to act intelligently.</li>
<li>üóπ Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed.</li>
</ul>
</li>
</ol>
<h3 id="linear-regression-with-one-variable-" style="position:relative;"><a href="#linear-regression-with-one-variable-" aria-label="linear regression with one variable  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Linear Regression with One Variable :</h3>
<ol>
<li>
<p>Consider the problem of predicting how well a student does in her second year of college/university, given how well she did in her first year. Specifically, let x be equal to the number of ‚ÄúA‚Äù grades (including A-. A and A+ grades) that a student receives in their first year of college (freshmen year). We would like to predict the value of y, which we define as the number of ‚ÄúA‚Äù grades they get in their second year (sophomore year).<br>
Here each row is one training example. Recall that in linear regression, our hypothesis is $h<em>\theta(x)=\theta</em>0+\theta<em>1x$ to denote the number of training examples.<br>
![enter image description here](</em>v<em>images/20210106042809097</em>6366.png)<br>
For the training set given above (note that this training set may also be referenced in other questions in this $m$)? In the box below, please enter your answer (which should be a number between 0 and 10).  </p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="0"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">4 </span></span></code></pre>
</li>
<li>
<p>Many substances that can burn (such as gasoline and alcohol) have a chemical structure based on carbon atoms; for this reason they are called hydrocarbons. A chemist wants to understand how the number of carbon atoms in a molecule affects how much energy is released when that molecule combusts (meaning that it is burned). The chemist obtains the dataset below. In the column on the right, ‚ÄúkJ/mol‚Äù is the unit measuring the amount of energy released.  </p>
<p><img src="_v_images/20210106042807663_5970.png" alt="enter image description here">  </p>
<p> You would like to use linear regression $h<em>\theta(x) = \theta</em>0 + \theta<em>1x$ to estimate the amount of energy released (y) as a function of the number of carbon atoms (x). Which of the following do you think will be the values you obtain for $\theta</em>0$ and $\theta_1$ ? You should be able to select the right answer without actually implementing linear regression.  </p>
<ul>
<li>‚òê $\theta<em>0$ = ‚àí569.6, $\theta</em>1$ = 530.9</li>
<li>‚òê $\theta<em>0$ = ‚àí1780.0, $\theta</em>1$ = ‚àí530.9</li>
<li>üóπ $\theta<em>0$ = ‚àí569.6, $\theta</em>1$ = ‚àí530.9</li>
<li>‚òê $\theta<em>0$ = ‚àí1780.0, $\theta</em>1$ = 530.9</li>
</ul>
</li>
<li>
<p>For this question, assume that we are using the training set from Q1.<br>
Recall our definition of the cost function was $J(\theta<em>0, \theta</em>1 ) = \frac{1}{2m} \sum_{i=1}^{m} (h (x^{(i)} ) - y^{(i)})^2$<br>
What is $J(0,1)$? In the box below,<br>
please enter your answer (Simplify fractions to decimals when entering answer, and ‚Äò.‚Äô as the decimal delimiter e.g., 1.5).  </p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="1"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">0.5</span></span></code></pre>
</li>
<li>
<p>Suppose we set $\theta<em>0 = 0, \theta</em>1 = 1.5$ in the linear regression hypothesis from Q1. What is $h_\theta(2)$ ?  </p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="2"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">3</span></span></code></pre>
</li>
<li>
<p>Suppose we set $\theta<em>0 = -2, \theta</em>1 = 0.5$ in the linear regression hypothesis from Q1. What is $h_\theta(6)$?  </p>
<pre class="grvsc-container one-dark-pro" data-language="" data-index="3"><code class="grvsc-code"><span class="grvsc-line"><span class="grvsc-source">1</span></span></code></pre>
</li>
<li>
<p>Let $f$ be some function so that $f(\theta<em>0 , \theta</em>1 )$ outputs a number. For this problem, f is some arbitrary/unknown smooth function (not necessarily the cost function of linear regression, so f may have local optima).
Suppose we use gradient descent to try to minimize $f(\theta<em>0 , \theta</em>1 )$ as a function of $\theta<em>0$ and $\theta</em>1$.
Which of the following statements are true? (Check all that apply.)</p>
<ul>
<li>üóπ If $\theta<em>0$ and $\theta</em>1$ are initialized at the global minimum, then one iteration will not change their values.</li>
<li>‚òê Setting the learning rate $\alpha$ to be very small is not harmful, and can only speed up the convergence of gradient descent.</li>
<li>‚òê No matter how $\theta<em>0$ and $\theta</em>1$ are initialized, so long as $\alpha$ is sufficiently small, we can safely expect gradient descent to converge to the same solution.</li>
<li>üóπ  If the first few iterations of gradient descent cause $f(\theta<em>0 , \theta</em>1)$ to increase rather than decrease, then the most likely cause is that we have set the learning rate $\alpha$ to too large a value.</li>
</ul>
</li>
<li>
<p>In the given figure, the cost function $J(\theta<em>0, \theta</em>1)$ has been plotted against $\theta<em>0$ and $\theta</em>1$, as shown in ‚ÄòPlot 2‚Äô. The contour plot for the same cost function is given in ‚ÄòPlot 1‚Äô. Based on the figure, choose the correct options (check all that apply).
<img src="_v_images/20210106045949479_13558.png" alt="Plots for Cost Function"></p>
<ul>
<li>‚òê If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point A, as the value of cost function $J(\theta<em>0, \theta</em>1)$ is maximum at point A.</li>
<li>‚òê If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point C, as the value of cost function $J(\theta<em>0, \theta</em>1)$ is minimum at point C.</li>
<li>üóπ Point P (the global minimum of plot 2) corresponds to point A of Plot 1.</li>
<li>üóπ If we start from point B, gradient descent with a well-chosen learning rate will eventually help us reach at or near point A, as the value of cost function $J(\theta<em>0, \theta</em>1)$ is minimum at A.</li>
<li>‚òê Point P (The global minimum of plot 2) corresponds to point C of Plot 1.</li>
</ul>
</li>
<li>
<p>Suppose that for some linear regression problem (say, predicting housing prices as in the lecture), we have some training set, and for our training set we managed to find some $\theta<em>0, \theta</em>1$, such that $J(\theta<em>0 , \theta</em>1) = 0$.
Which of the statements below must then be true? (Check all that apply.)</p>
<ul>
<li>‚òê Gradient descent is likely to get stuck at a local minimum and fail to find the global minimum.</li>
<li>‚òê For this to be true, we must have $\theta<em>0 = 0$ and $\theta</em>1 = 0$
so that $h_{\theta}(x) = 0$</li>
<li>‚òê For this to be true, we must have $y^{(i)} = 0$ for every value of $i = 1, 2,‚Ä¶,m$.</li>
<li>üóπ Our training set can be fit perfectly by a straight line, i.e., all of our training examples lie perfectly on some straight line.</li>
</ul>
</li>
</ol>
<h2 id="week-4" style="position:relative;"><a href="#week-4" aria-label="week 4 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Week 4</h2>
<h3 id="logistic-regression-" style="position:relative;"><a href="#logistic-regression-" aria-label="logistic regression  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Logistic Regression :</h3>
<ol>
<li>
<p>Suppose that you have trained a logistic regression classifier, and it outputs on a new example a prediction $h_\theta(x) = 0.2$. This means (check all that apply):</p>
<ul>
<li>‚òê Our estimate for P(y = 1|x; Œ∏) is 0.8.</li>
<li>üóπ Our estimate for P(y = 0|x; Œ∏) is 0.8.</li>
<li>üóπ Our estimate for P(y = 1|x; Œ∏) is 0.2.</li>
<li>‚òê Our estimate for P(y = 0|x; Œ∏) is 0.2.</li>
</ul>
</li>
<li>
<p>Suppose you have the following training set, and fit a logistic regression classifier $h<em>\theta(x) = g(\theta</em>0 + \theta<em>1x</em>1 + \theta<em>2x</em>2)$.
Which of the following are true? Check all that apply.
<img src="_v_images/20210106083228677_5192.png">
<img src="_v_images/20210106083244202_2232.png"></p>
<ul>
<li>üóπ Adding polynomial features (e.g., instead using $h<em>\theta(x) = g(\theta</em>0 + \theta<em>1 x</em>1 + \theta<em>2 x</em>2 + \theta<em>3 x</em>1^2 + \theta<em>4 x</em>1 x<em>2 + \theta</em>5 x_2^2 ))$ could increase how well we can fit the training data.</li>
<li>üóπ At the optimal value of Œ∏ (e.g., found by fminunc), we will have $J(Œ∏) ‚â• 0$.</li>
<li>‚òê Adding polynomial features (e.g., instead using $h<em>\theta(x) = g(\theta</em>0 + \theta<em>1 x</em>1 + \theta<em>2 x</em>2 + \theta<em>3 x</em>1^2 + \theta<em>4 x</em>1 x<em>2 + \theta</em>5 x_2^2 ))$ would increase $J(Œ∏)$ because we are now summing over more terms.</li>
<li>‚òê If we train gradient descent for enough iterations, for some examples $x^{(i)}$ in the training set it is possible to obtain $h_\theta(x^{(i)} ) > 1$.</li>
</ul>
</li>
<li>
<p>For logistic regression, the gradient is given by $\frac{\partial }{\partial \theta<em>j } J(\theta) = \frac{1}{m} \sum</em>{i=1}^{m}(h<em>\theta(x^{(i)})-y^{i})x^{(i)}</em>j$. Which of these is a correct gradient descent update for logistic regression with a learning rate of $\alpha$ ? Check all that apply.</p>
<ul>
<li>üóπ $\theta<em>j := \theta</em>j - \alpha \frac{1}{m} \sum<em>{i=1}^m (h</em>\theta(x^{(i)-y^i}) x^{(i)}_j$ (simultaneously update for all j).</li>
<li>‚òê $\theta := \theta - \alpha \frac{1}{m} \sum_{i=1}^m (\theta^Tx-y^{(i)}) x^{(i)}$.</li>
<li>üóπ $\theta<em>j := \theta</em>j - \alpha \frac{1}{m} \sum<em>{i=1}^m \left(\frac{1}{1+e^{-\theta^Tx^{(i)}}}-y^{(i)}\right) x^{(i)}</em>j$ (simultaneously update for all j).</li>
<li>‚òê $\theta<em>j := \theta</em>j - \alpha \frac{1}{m} \sum<em>{i=1}^m (h</em>\theta(x^{(i)-y^i}) x^{(i)}$ (simultaneously update for all j).</li>
</ul>
</li>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>üóπ The one-vs-all technique allows you to use logistic regression for problems in which each $y^{(i)}$ comes from a fixed, discrete set of values.</li>
<li>‚òê For logistic regression, sometimes gradient descent will converge to a local minimum (and fail to find the global minimum). This is the reason we prefer more advanced optimization algorithms such as fminunc (conjugate gradient/BFGS/L-BFGS/etc).</li>
<li>üóπ The cost function $J(\theta)$ for logistic regression trained with $m \geq 1$ examples is always greater than or equal to zero.</li>
<li>‚òê Since we train one classifier when there are two classes, we train two classifiers when there are three classes (and we do one-vs-all classification).</li>
</ul>
</li>
<li>
<p>Suppose you train a logistic classifier $h<em>\theta(x) = g(\theta</em>0 + \theta<em>1x</em>1 + \theta<em>2x</em>2)$. Suppose $\theta<em>0 = 6$, $\theta</em>1 = -1$, $\theta_2 = 0$. Which of the following figures represents the decision boundary found by your classifier?</p>
<ul>
<li>üóπ  Figure:
<img src="_v_images/20210106084140048_15600.png"></li>
<li>‚òê  Figure:
<img src="_v_images/20210106084157413_13022.png"></li>
<li>‚òê  Figure:
<img src="_v_images/20210106084209408_957.png"></li>
<li>‚òê  Figure:
<img src="_v_images/20210106084222258_31191.png"></li>
</ul>
</li>
</ol>
<h3 id="regularization" style="position:relative;"><a href="#regularization" aria-label="regularization permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Regularization</h3>
<ol>
<li>
<p>You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.</p>
<ul>
<li>‚òê Introducing regularization to the model always results in equal or better performance on the training set.</li>
<li>‚òê Introducing regularization to the model always results in equal or better performance on examples not in the training set.</li>
<li>üóπ Adding a new feature to the model always results in equal or better performance on the training set.</li>
<li>‚òê Adding many new features to the model helps prevent overfitting on the training set.</li>
</ul>
</li>
<li>
<p>Suppose you ran logistic regression twice, once with $\lambda = 0$, and once with $\lambda = 1$. One of the times, you got parameters $\theta = \begin{bmatrix} 74.81\ 45.05 \end{bmatrix}$, and the other time you got $\theta = \begin{bmatrix} 1.37\ 0.51 \end{bmatrix}$. However, you forgot which value of $\lambda$ corresponds to which value of $\theta$. Which one do you think corresponds to $\lambda = 1$?</p>
<ul>
<li>üóπ $\theta = \begin{bmatrix} 1.37\ 0.51 \end{bmatrix}$</li>
<li>‚òê $\theta = \begin{bmatrix} 74.81\ 45.05 \end{bmatrix}$</li>
</ul>
</li>
<li>
<p>Which of the following statements about regularization are true? Check all that apply.</p>
<ul>
<li>‚òê Using a very large value of $\lambda$ hurt the performance of your hypothesis; the only reason we do not set $\lambda$ to be too large is to avoid numerical problems.</li>
<li>‚òê Because logistic regression outputs values $0 \leq h_\theta(x) \leq 1$, its range of output values can only be ‚Äúshrunk‚Äù slightly by regularization anyway, so regularization is generally not helpful for it.</li>
<li>üóπ Consider a classification problem. Adding regularization may cause your classifier to incorrectly classify some training examples (which it had correctly classified when not using regularization, i.e. when $\lambda = 0$).</li>
<li>‚òê Using too large a value of $\lambda$ can cause your hypothesis to overfit the data; this can be avoided by reducing $\lambda$.</li>
</ul>
</li>
<li>
<p>Which of the following statements about regularization are true? Check all that apply.</p>
<ul>
<li>‚òê Using a very large value of $\lambda$ hurt the performance of your hypothesis; the only reason we do not set $\lambda$ to be too large is to avoid numerical problems.</li>
<li>‚òê Because logistic regression outputs values $0 \leq h_\theta(x) \leq 1$, its range of output values can only be ‚Äúshrunk‚Äù slightly by regularization anyway, so regularization is generally not helpful for it.</li>
<li>‚òê Because regularization causes $J(\theta)$ to no longer be convex, gradient descent may not always converge to the global minimum (when $\lambda > 0$, and when using an appropriate learning rate $\alpha$).</li>
<li>üóπ Using too large a value of $\lambda$ can cause your hypothesis to underfit the data; this can be avoided by reducing $\lambda$.</li>
</ul>
</li>
<li>
<p>In which one of the following figures do you think the hypothesis has <strong>overfit</strong> the training set?</p>
<ul>
<li>üóπ Figure:<br>
<img src="_v_images/20210106085327397_3544.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085326883_11633.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085326168_15899.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085325553_12712.png" alt="enter image description here"></li>
</ul>
</li>
<li>
<p>In which one of the following figures do you think the hypothesis has <strong>underfit</strong> the training set?</p>
<ul>
<li>üóπ Figure:<br>
<img src="_v_images/20210106085459252_8922.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085458644_4792.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085457929_4685.png" alt="enter image description here"></li>
<li>‚òê Figure:<br>
<img src="_v_images/20210106085457521_31575.png" alt="enter image description here"></li>
</ul>
</li>
</ol>
<h2 id="week-5" style="position:relative;"><a href="#week-5" aria-label="week 5 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Week 5</h2>
<h3 id="neural-networks---representation-" style="position:relative;"><a href="#neural-networks---representation-" aria-label="neural networks   representation  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Neural Networks - Representation :</h3>
<ol>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>üóπ Any logical function over binary-valued (0 or 1) inputs $x<em>1$ and $x</em>2$ can be (approximately) represented using some neural network.</li>
<li>‚òê Suppose you have a multi-class classification problem with three classes, trained with a 3 layer network. Let $a^{(3)}<em>1 = (h</em>\theta(x))<em>1$ be the activation of the first output unit, and similarly $a^{(3)}</em>2 = (h<em>\theta(x))</em>2$ and $a^{(3)}<em>3 = (h</em>\theta(x))<em>3$. Then for any input x, it must be the case that $a^{(3)}</em>1 + a^{(3)}<em>2 + a^{(3)}</em>3 = 1$.</li>
<li>‚òê A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function.</li>
<li>üóπ The activation values of the hidden units in a neural network, with the sigmoid activation function applied at every layer, are always in the range (0, 1).</li>
</ul>
</li>
<li>
<p>Consider the following neural network which takes two binary-valued inputs
$x<em>1,x</em>2 \ \epsilon \ {0,1}$ and outputs $h<em>\theta(x)$. Which of the following logical functions does it (approximately) compute?
![](</em>v<em>images/20210106090915082</em>15939.png)</p>
<ul>
<li>üóπ AND</li>
<li>‚òê NAND (meaning ‚ÄúNOT AND‚Äù)</li>
<li>‚òê OR</li>
<li>‚òê XOR (exclusive OR)</li>
</ul>
</li>
<li>
<p>Consider the following neural network which takes two binary-valued inputs
$x<em>1,x</em>2 \ \epsilon \ {0,1}$ and outputs $h<em>\theta(x)$. Which of the following logical functions does it (approximately) compute?
![](</em>v<em>images/20210106091216256</em>21503.png)</p>
<ul>
<li>‚òê AND</li>
<li>‚òê NAND (meaning ‚ÄúNOT AND‚Äù)</li>
<li>üóπ OR</li>
<li>‚òê XOR (exclusive OR)</li>
</ul>
</li>
<li>
<p>Consider the neural network given below. Which of the following equations correctly computes the activation $a<em>1^{(3)}$? Note: $g(z)$ is the sigmoid activation function.
![](</em>v<em>images/20210106091606930</em>29779.png)</p>
<ul>
<li>üóπ $a<em>1^{(3)} = g(\theta</em>{1,0}^{(2)}a<em>0^{(2)}+\theta</em>{1,1}^{(2)}a<em>1^{(2)}+\theta</em>{1,2}^{(2)}a_2^{(2)})$</li>
<li>‚òê $a<em>1^{(3)} = g(\theta</em>{1,0}^{(2)}a<em>0^{(1)}+\theta</em>{1,1}^{(2)}a<em>1^{(1)}+\theta</em>{1,2}^{(2)}a_2^{(1)})$</li>
<li>‚òê $a<em>1^{(3)} = g(\theta</em>{1,0}^{(1)}a<em>0^{(2)}+\theta</em>{1,1}^{(1)}a<em>1^{(2)}+\theta</em>{1,2}^{(1)}a_2^{(2)})$</li>
<li>‚òê $a<em>1^{(3)} = g(\theta</em>{2,0}^{(2)}a<em>0^{(2)}+\theta</em>{2,1}^{(2)}a<em>1^{(2)}+\theta</em>{2,2}^{(2)}a_2^{(2)})$</li>
</ul>
</li>
<li>
<p>You have the following neural network:
<img src="_v_images/20210106092659353_25197.png">
You‚Äôd like to compute the activations of the hidden layer $a^{(2)} \ \epsilon \ R^3$. One way to do
so is the following Octave code:
<img src="_v_images/20210106092714486_4049.png">
You want to have a vectorized implementation of this (i.e., one that does not use for loops). Which of the following implementations correctly compute ? Check all
that apply.</p>
<ul>
<li>üóπ <code>z = Theta1 * x; a2 = sigmoid (z);</code></li>
<li>‚òê <code>a2 = sigmoid (x * Theta1);</code></li>
<li>‚òê <code>a2 = sigmoid (Theta2 * x);</code></li>
<li>‚òê <code>z = sigmoid(x); a2 = sigmoid (Theta1 * z);</code></li>
</ul>
</li>
<li>
<p>You are using the neural network pictured below and have learned the parameters $\theta^{(1)} = \begin{bmatrix} 1 &#x26; 1 &#x26; 2.4\ 1 &#x26; 1.7 &#x26; 3.2 \end{bmatrix}$ (used to compute $a^{(2)}$) and $\theta^{(2)} = \begin{bmatrix} 1 &#x26; 0.3 &#x26; -1.2 \end{bmatrix}$ (used to compute $a^{(3)}$ as a function of $a^{(2)}$). Suppose you swap the parameters for the first hidden layer between its two units so $\theta^{(1)} = \begin{bmatrix} 1 &#x26; 1.7 &#x26; 3.2 \ 1 &#x26; 1 &#x26; 2.4 \end{bmatrix}$ and also swap the output layer so $\theta^{(2)} = \begin{bmatrix} 1 &#x26; -1.2 &#x26; 0.3 \end{bmatrix}$. How will this change the value of the output $h<em>\theta(x)$?
![](</em>v<em>images/20210106100117145</em>12734.png)</p>
<ul>
<li>üóπ It will stay the same.</li>
<li>‚òê It will increase.</li>
<li>‚òê It will decrease</li>
<li>‚òê Insufficient information to tell: it may increase or decrease.</li>
</ul>
</li>
</ol>
<h3 id="neural-networks-learning-" style="position:relative;"><a href="#neural-networks-learning-" aria-label="neural networks learning  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Neural Networks: Learning :</h3>
<ol>
<li>
<p>You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update $\Delta<em>{ij}^{(2)} := \Delta</em>{ij}^{(2)} + \delta<em>i^{(3)} * (a^{(2)})</em>j$
for every i,j. Which of the following is a correct vectorization of this step?</p>
<ul>
<li>‚òê $\Delta^{(2)} := \Delta^{(2)} + \delta^{(2)} * (a^{(3)})^T$</li>
<li>‚òê $\Delta^{(2)} := \Delta^{(2)} + (a^{(2)})^T * \delta^{(3)}$</li>
<li>‚òê $\Delta^{(2)} := \Delta^{(2)} + (a^{(2)})^T * \delta^{(2)}$</li>
<li>üóπ $\Delta^{(2)} := \Delta^{(2)} + \delta^{(3)} * (a^{(2)})^T$</li>
</ul>
</li>
<li>
<p>Suppose Theta1 is a 5x3 matrix, and Theta2 is a 4x6 matrix. You set thetaVec = [Theta1( : ), Theta2( : )]. Which of the following correctly recovers ?</p>
<ul>
<li>üóπ reshape(thetaVec(16 : 39), 4, 6)</li>
<li>‚òê reshape(thetaVec(15 : 38), 4, 6)</li>
<li>‚òê reshape(thetaVec(16 : 24), 4, 6)</li>
<li>‚òê reshape(thetaVec(15 : 39), 4, 6)</li>
<li>‚òê reshape(thetaVec(16 : 39), 6, 4)</li>
</ul>
</li>
<li>
<p>Let $J(\theta) = 2\theta^3 + 2$. Let $\theta = 1$, and $\epsilon = 0.01$. Use the formula $\frac{J{(\theta + \epsilon)}-J{(\theta - \epsilon)}}{2\epsilon}$ to numerically compute an approximation to the derivative at $\theta = 1$. What value do you get? (When $\theta = 1$, the true/exact derivative is $\frac{\mathrm{d} J(\theta)}{\mathrm{d} \theta} = 6$.)</p>
<ul>
<li>‚òê 8</li>
<li>üóπ 6.0002</li>
<li>‚òê 6</li>
<li>‚òê 5.9998</li>
</ul>
</li>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>üóπ For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network.</li>
<li>‚òê Computing the gradient of the cost function in a neural network has the same efficiency when we use backpropagation or when we numerically compute it using the method of gradient checking.</li>
<li>üóπ Using gradient checking can help verify if one‚Äôs implementation of backpropagation is bug-free.</li>
<li>‚òê Gradient checking is useful if we are using one of the advanced optimization methods (such as in fminunc) as our optimization algorithm. However, it serves little purpose if we are using gradient descent.</li>
</ul>
</li>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>üóπ If we are training a neural network using gradient descent, one reasonable ‚Äúdebugging‚Äù step to make sure it is working is to plot $J(\theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.</li>
<li>‚òê Suppose you have a three layer network with parameters $\theta^{(1)}$ (controlling the function mapping from the inputs to the hidden units) and $\theta^{(2)}$ (controlling the mapping from the hidden units to the outputs). If we set all the elements of $\theta^{(1)}$ to be 0, and all the elements of $\theta^{(2)}$ to be 1, then this suffices for symmetry breaking, since the neurons are no longer all computing the same function of the input.</li>
<li>üóπ Suppose you are training a neural network using gradient descent. Depending on your random initialization, your algorithm may converge to different local optima (i.e., if you run the algorithm twice with different random initializations, gradient descent may converge to two different solutions).</li>
<li>‚òê If we initialize all the parameters of a neural network to ones instead of zeros, this will suffice for the purpose of ‚Äúsymmetry breaking‚Äù because the parameters are no longer symmetrically equal to zero.</li>
</ul>
</li>
</ol>
<h2 id="week-6" style="position:relative;"><a href="#week-6" aria-label="week 6 permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Week 6</h2>
<h3 id="advice-for-applying-machine-learning-" style="position:relative;"><a href="#advice-for-applying-machine-learning-" aria-label="advice for applying machine learning  permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Advice for Applying Machine Learning :</h3>
<ol>
<li>
<p>You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?
<img src="_v_images/20210106114811822_23068.png"></p>
<ul>
<li>‚òê High variance</li>
<li>‚òê Neither</li>
<li>üóπ High bias</li>
</ul>
</li>
<li>
<p>You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?
<img src="_v_images/20210106115114688_20798.png"></p>
<ul>
<li>üóπ High variance</li>
<li>‚òê Neither</li>
<li>‚òê High bias</li>
</ul>
</li>
<li>
<p>Suppose you have implemented regularized logistic regression to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large errors with its predictions on the new images. However, your hypothesis performs well (has low error) on the training set. Which of the following are promising steps to take? Check all that apply.
NOTE: Since the hypothesis performs well (has low error) on the training set, it is suffering from high variance (overfitting)</p>
<ul>
<li>‚òê Try adding polynomial features.</li>
<li>‚òê Use fewer training examples.</li>
<li>üóπ  Try using a smaller set of features.</li>
<li>üóπ Get more training examples.</li>
<li>‚òê Try evaluating the hypothesis on a cross validation set rather than the test set.</li>
<li>‚òê Try decreasing the regularization parameter Œª.</li>
<li>üóπ Try increasing the regularization parameter Œª.</li>
</ul>
</li>
<li>
<p>Suppose you have implemented regularized logistic regression to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis performs poorly on the training set. Which of the following might be promising steps to take? Check all that apply.
NOTE: Since the hypothesis performs poorly on the training set, it is suffering from high bias (underfitting)</p>
<ul>
<li>‚òê Try increasing the regularization parameter Œª.</li>
<li>üóπ Try decreasing the regularization parameter Œª.</li>
<li>‚òê Try evaluating the hypothesis on a cross validation set rather than the test set.</li>
<li>‚òê Use fewer training examples.</li>
<li>üóπ Try adding polynomial features.</li>
<li>‚òê Try using a smaller set of features.</li>
<li>üóπ Try to obtain and use additional features.</li>
</ul>
</li>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>‚òê Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter to use is to choose the value of which gives the lowest test set error.</li>
<li>‚òê Suppose you are training a regularized linear regression model.The recommended way to choose what value of regularization parameter to use is to choose the value of which gives the lowest training set error.</li>
<li>üóπ The performance of a learning algorithm on the training set will typically be better than its performance on the test set.</li>
<li>üóπ Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter to use is to choose the value of which gives the lowest cross validation error.</li>
<li>üóπ A typical split of a dataset into training, validation and test sets might be 60% training set, 20% validation set, and 20% test set.</li>
<li>‚òê Suppose you are training a logistic regression classifier using polynomial features and want to select what degree polynomial (denoted in the lecture videos) to use. After training the classifier on the entire training set, you decide to use a subset of the training examples as a validation set. This will work just as well as having a validation set that is separate (disjoint) from the training set.</li>
<li>‚òê It is okay to use data from the test set to choose the regularization parameter Œª, but not the model parameters (Œ∏).</li>
<li>üóπ Suppose you are using linear regression to predict housing prices, and your dataset comes sorted in order of increasing sizes of houses. It is then important to randomly shuffle the dataset before splitting it into training, validation and test sets, so that we don‚Äôt have all the smallest houses going into the training set, and all the largest houses going into the test set.</li>
</ul>
</li>
<li>
<p>Which of the following statements are true? Check all that apply.</p>
<ul>
<li>üóπ A model with more parameters is more prone to overfitting and typically has higher variance.</li>
<li>‚òê If the training and test errors are about the same, adding more features will not help improve the results.</li>
<li>üóπ If a learning algorithm is suffering from high bias, only adding more training examples may not improve the test error significantly.</li>
<li>üóπ If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.</li>
<li>üóπ When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem.</li>
<li>‚òê If a neural network has much lower training error than test error, then adding more layers will help bring the test error down because we can fit the test set better.</li>
</ul>
</li>
</ol>
<h2 id="links" style="position:relative;"><a href="#links" aria-label="links permalink" class="toc-header before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Links</h2>
<ul>
<li><a href="https://github.com/LiMengyang990726/Coursera-Machine-Learning/blob/master/Machine-Learning/Week1Quiz.md">Coursera-Machine-Learning/Week1Quiz.md at master ¬∑ LiMengyang990726/Coursera-Machine-Learning</a></li>
<li><a href="https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford">atinesh-s/Coursera-Machine-Learning-Stanford: Machine learning-Stanford University</a></li>
<li><a href="https://www.codemummy.com/p/coursera-machine-learning-andrew-ng-all.html">Coursera-Machine Learning - Andrew NG - All weeks solutions of assignments and quiz - codemummy |online technical computer science platform.</a></li>
<li><a href="https://github.com/mGalarnyk/datasciencecoursera/tree/master/Stanford_Machine_Learning">datasciencecoursera/Stanford<em>Machine</em>Learning at master ¬∑ mGalarnyk/datasciencecoursera</a></li>
<li><a href="https://www.apdaga.com/search/label/Machine%20Learning?updated-max=2019-11-14T15:01:00%2B05:30&#x26;max-results=20&#x26;start=20&#x26;by-date=false">APDaga DumpBox : The Thirst for Learning...: Machine Learning</a></li>
</ul>
<style class="grvsc-styles">
  .grvsc-container {
    overflow: auto;
    position: relative;
    -webkit-overflow-scrolling: touch;
    padding-top: 1rem;
    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));
    padding-bottom: 1rem;
    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));
    border-radius: 8px;
    border-radius: var(--grvsc-border-radius, 8px);
    font-feature-settings: normal;
    line-height: 1.4;
  }
  
  .grvsc-code {
    display: table;
  }
  
  .grvsc-line {
    display: table-row;
    box-sizing: border-box;
    width: 100%;
    position: relative;
  }
  
  .grvsc-line > * {
    position: relative;
  }
  
  .grvsc-gutter-pad {
    display: table-cell;
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  .grvsc-gutter {
    display: table-cell;
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter::before {
    content: attr(data-content);
  }
  
  .grvsc-source {
    display: table-cell;
    padding-left: 1.5rem;
    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));
    padding-right: 1.5rem;
    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));
  }
  
  .grvsc-source:empty::after {
    content: ' ';
    -webkit-user-select: none;
    -moz-user-select: none;
    user-select: none;
  }
  
  .grvsc-gutter + .grvsc-source {
    padding-left: 0.75rem;
    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);
  }
  
  /* Line transformer styles */
  
  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {
    content: ' ';
    position: absolute;
    width: 100%;
  }
  
  .grvsc-line-diff-add::before {
    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));
  }
  
  .grvsc-line-diff-del::before {
    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));
  }
  
  .grvsc-line-number {
    padding: 0 2px;
    text-align: right;
    opacity: 0.7;
  }
  
  .one-dark-pro {
    background-color: #282c34;
    color: #abb2bf;
  }
  .one-dark-pro .grvsc-line-highlighted::before {
    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));
    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));
  }
</style></div></div></div></div><div class="css-1bdwg0l eyldt480"><div><style data-emotion-css="17t5ffy">.css-17t5ffy{margin-top:1rem;margin-bottom:1rem;}</style><div class="css-17t5ffy"><div class="css-1l4w6pd"><div class="css-yapsbb"></div></div></div><style data-emotion-css="i1cgbm">.css-i1cgbm{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;margin-top:1rem;padding-left:0.5rem;padding-right:0.5rem;}</style><div class="css-i1cgbm"><style data-emotion-css="16k19ub">.css-16k19ub{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#2D87FD;}</style><button class="css-16k19ub"><style data-emotion-css="u7tj59">.css-u7tj59{fill:currentColor;margin-top:auto;margin-bottom:auto;margin-right:0.25rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 320 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z"></path></svg>Share with <!-- -->Facebook</button><style data-emotion-css="9nr5sz">.css-9nr5sz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#1CA1F2;}</style><button class="css-9nr5sz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>Share with <!-- -->Twitter</button><style data-emotion-css="rk0yc0">.css-rk0yc0{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;margin-left:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#6E7783;}</style><button class="css-rk0yc0"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-u7tj59" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg>Share with <!-- -->Url</button></div></div><style data-emotion-css="14e3tt2">.css-14e3tt2{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;padding-left:0.5rem;padding-right:0.5rem;}</style><div class="css-14e3tt2"><style data-emotion-css="1cwag5x">.css-1cwag5x{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:0.75rem;padding-right:0.75rem;padding-top:0.25rem;padding-bottom:0.25rem;margin-top:0.5rem;margin-bottom:0.5rem;border-radius:0.25rem;--text-opacity:1;color:rgba(255,255,255,var(--text-opacity));background-color:#FF813E;}</style><a target="_blank" rel="noopener noreferrer" href="https://www.buymeacoffee.com/irosyadi" class="css-1cwag5x"><style data-emotion-css="9u48bm">.css-9u48bm{margin-right:0.5rem;}</style><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="Buy me tea or coffee ;)" class="css-9u48bm"/><span>Buy me tea</span></a></div></div></div></div><div class="css-1bdwg0l eyldt480"><style data-emotion-css="17t1oy1">.css-17t1oy1{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap-reverse;-ms-flex-wrap:wrap-reverse;flex-wrap:wrap-reverse;margin-left:0.5rem;margin-right:0.5rem;margin-top:1rem;}@media (min-width:768px){.css-17t1oy1{-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}}</style><div class="css-17t1oy1 e816y8n0"><style data-emotion-css="1pwr1ry">.css-1pwr1ry{width:100%;margin:0.5rem;}@media (min-width:768px){.css-1pwr1ry{width:50%;margin:1rem;}}</style><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="vl2eok">.css-vl2eok{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:left;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-left-width:4px;border-color:#86a8e7;}.css-vl2eok:hover{background-color:#ddd;}</style><a rel="prev" class="css-vl2eok" href="/catatan/ml-untuk-siapa-saja/"><style data-emotion-css="19o7xeo">.css-19o7xeo{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;margin-right:1rem;margin-left:0.5rem;height:100%;}</style><div class="css-19o7xeo"><style data-emotion-css="11za1ik">.css-11za1ik{width:2rem;height:2rem;margin-top:auto;margin-bottom:auto;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M872 474H286.9l350.2-304c5.6-4.9 2.2-14-5.2-14h-88.5c-3.9 0-7.6 1.4-10.5 3.9L155 487.8a31.96 31.96 0 0 0 0 48.3L535.1 866c1.5 1.3 3.3 2 5.2 2h91.5c7.4 0 10.8-9.2 5.2-14L286.9 550H872c4.4 0 8-3.6 8-8v-60c0-4.4-3.6-8-8-8z"></path></svg></div><style data-emotion-css="v38or">.css-v38or{display:inline-block;margin-top:0.5rem;margin-bottom:0.5rem;}</style><div class="css-v38or"><style data-emotion-css="2m7hin">.css-2m7hin{color:#3737B9;}</style><p class="css-2m7hin">Previous Post</p><p>Machine Learning untuk Siapa Saja</p></div></a></div><div class="css-1pwr1ry e816y8n1"><style data-emotion-css="xhvfnc">.css-xhvfnc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);text-align:right;width:100%;height:100%;padding:0.5rem;background-color:#eee;border-radius:0.25rem;border-right-width:4px;border-color:#86a8e7;}.css-xhvfnc:hover{background-color:#ddd;}</style><a rel="next" class="css-xhvfnc" href="/howto/anaconda-howto/"><div class="css-v38or"><p class="css-2m7hin">Next Post</p><p>Anaconda Howto</p></div><div class="css-19o7xeo"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-11za1ik" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M869 487.8L491.2 159.9c-2.9-2.5-6.6-3.9-10.5-3.9h-88.5c-7.4 0-10.8 9.2-5.2 14l350.2 304H152c-4.4 0-8 3.6-8 8v60c0 4.4 3.6 8 8 8h585.1L386.9 854c-5.6 4.9-2.2 14 5.2 14h91.5c1.9 0 3.8-.7 5.2-2L869 536.2a32.07 32.07 0 0 0 0-48.4z"></path></svg></div></a></div></div><style data-emotion-css="14yohw7">.css-14yohw7{width:100%;max-width:768px;padding-left:1rem;padding-right:1rem;margin-left:auto;margin-right:auto;padding-top:2rem;margin-top:0.5rem;margin-bottom:1rem;}@media (min-width:768px){.css-14yohw7{padding-left:0;padding-right:0;padding-top:3rem;}}</style><div class="css-14yohw7 e16bs3iv0"><style data-emotion-css="180ky7f">.css-180ky7f{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:0.5rem;padding-right:0.5rem;}@media (min-width:768px){.css-180ky7f{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style><div class="css-180ky7f e16bs3iv1"><style data-emotion-css="p5b1u1">.css-p5b1u1{border-radius:9999px;border-width:1px;--border-opacity:1;border-color:rgba(214,188,250,var(--border-opacity));margin-right:2rem;margin-bottom:0.5rem;}@media (min-width:768px){.css-p5b1u1{margin-bottom:1rem;}}</style><div class="css-p5b1u1 gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:128px;height:128px"><img aria-hidden="true" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB34pUAAH/xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAEFAh//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAUEAEAAAAAAAAAAAAAAAAAAAAw/9oACAEBAAY/Ah//xAAWEAEBAQAAAAAAAAAAAAAAAAAgASH/2gAIAQEAAT8hp0f/2gAMAwEAAgADAAAAEGAHPP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EABsQAQACAwEBAAAAAAAAAAAAAAEAERAhQTGB/9oACAEBAAE/EFsDsqmxcXaPI78Z8M7n/9k=" alt="profileImg" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/14b96143ca546d8a3e6e66cdf41da63a/6dc0c/profile.jpg 1x,
/static/14b96143ca546d8a3e6e66cdf41da63a/cc017/profile.jpg 1.5x" /><img loading="lazy" width="128" height="128" srcset="/static/14b96143ca546d8a3e6e66cdf41da63a/6dc0c/profile.jpg 1x,
/static/14b96143ca546d8a3e6e66cdf41da63a/cc017/profile.jpg 1.5x" src="/static/14b96143ca546d8a3e6e66cdf41da63a/6dc0c/profile.jpg" alt="profileImg" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><div><span>Written by </span><style data-emotion-css="1t4jyca">.css-1t4jyca{display:inline-block;font-size:1.25rem;font-weight:700;border-radius:9999px;margin-bottom:0.5rem;padding-left:0.75rem;padding-right:0.75rem;--bg-opacity:1;background-color:rgba(237,242,247,var(--bg-opacity));color:#3737B9;}</style><p class="css-1t4jyca">@<!-- -->irosyadi</p><style data-emotion-css="vg2p6i">.css-vg2p6i{font-size:0.875rem;font-weight:400;margin-bottom:0.5rem;}</style><div class="css-vg2p6i">notes of a life</div></div></div><style data-emotion-css="1air669">.css-1air669{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-1air669"><div class="css-yapsbb"></div></div><style data-emotion-css="1baulvz">.css-1baulvz{display:inline-block;}</style><a title="github Link" href="https://github.com/irosyadi" class="css-1baulvz"><style data-emotion-css="vnd1fq">.css-vnd1fq{width:2rem;height:2rem;margin-top:1rem;margin-left:1rem;-webkit-transition:all 300ms cubic-bezier(0,0,0.2,1);transition:all 300ms cubic-bezier(0,0,0.2,1);color:#888;}.css-vnd1fq:hover{color:#000;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a title="facebook Link" href="https://www.facebook.com/profile.php?id=imron.rosyadi" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"></path></svg></a><a title="twitter Link" href="https://twitter.com/irosyadi" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a title="linkedin Link" href="https://www.linkedin.com/in/irosyadi" class="css-1baulvz"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="css-vnd1fq" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a></div><style data-emotion-css="18jj1tc">.css-18jj1tc{margin-top:1.25rem;margin-left:0.5rem;margin-right:0.5rem;}</style><div class="css-18jj1tc"><div class="utterances"></div></div></div></div><style data-emotion-css="xgi74q">.css-xgi74q{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;position:fixed;bottom:0;right:0;padding-right:1.5rem;padding-bottom:1.5rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}</style><div class="css-xgi74q e8huvi00"><style data-emotion-css="1a68u">.css-1a68u{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-content:flex-end;-ms-flex-line-pack:end;align-content:flex-end;z-index:100;}.css-1a68u:hover{background-color:#404040;color:#FFFFFF;}.css-1a68u:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="change to darkmode" class="css-1a68u"><style data-emotion-css="1alqh2e">.css-1alqh2e{fill:currentColor;--text-opacity:1;color:rgba(246,224,94,var(--text-opacity));width:1rem;height:1rem;margin-top:auto;margin-bottom:auto;margin-left:0;margin-right:0;}@media (min-width:768px){.css-1alqh2e{display:inline-block;margin-left:0.25rem;margin-right:0.25rem;}}</style><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="css-1alqh2e" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg><style data-emotion-css="flxr9x">.css-flxr9x{display:none;margin-right:0;}@media (min-width:768px){.css-flxr9x{display:inline-block;margin-right:0.25rem;}}</style><span class="css-flxr9x">dark</span></button><style data-emotion-css="15afv4q">.css-15afv4q{box-shadow:0 2px 2px 0 rgba(0,0,0,0.15);-webkit-transition:all 300ms cubic-bezier(0.4,0,0.2,1);transition:all 300ms cubic-bezier(0.4,0,0.2,1);background-color:#FFFFFF;color:#636363;font-size:0.75rem;padding-left:0.5rem;padding-right:0.5rem;padding-top:0.5rem;padding-bottom:0.5rem;border-radius:9999px;--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;-webkit-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));-ms-transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y));cursor:pointer;margin-left:0.5rem;margin-top:auto;margin-bottom:auto;z-index:100;}.css-15afv4q:hover{background-color:#404040;color:#FFFFFF;}.css-15afv4q:hover{--transform-scale-x:1.05;--transform-scale-y:1.05;}</style><button title="top page" class="css-15afv4q"><style data-emotion-css="13htjwu">.css-13htjwu{width:1rem;height:1rem;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="css-13htjwu" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M868 545.5L536.1 163a31.96 31.96 0 0 0-48.3 0L156 545.5a7.97 7.97 0 0 0 6 13.2h81c4.6 0 9-2 12.1-5.5L474 300.9V864c0 4.4 3.6 8 8 8h60c4.4 0 8-3.6 8-8V300.9l218.9 252.3c3 3.5 7.4 5.5 12.1 5.5h81c6.8 0 10.5-8 6-13.2z"></path></svg></button></div><style data-emotion-css="1k8xcyw">.css-1k8xcyw{text-align:center;padding-top:2rem;padding-bottom:2rem;bottom:0;}</style><footer class="css-1k8xcyw"><style data-emotion-css="1xju3od">.css-1xju3od{font-size:0.75rem;font-weight:700;}</style><a href="https://github.com/JaeSeoKim" class="css-1xju3od">¬©irosyadi with JaeSeoKim Theme</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-185820309-1', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/course/machine-learning-andrewng-quiz/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-2d63daeed7f68b4f099c.js"],"app":["/app-f6ca4d5f718b892ec182.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-5675fd69eeef62472b5e.js"],"component---src-pages-404-js":["/component---src-pages-404-js-55999d734654293c1340.js"],"component---src-pages-index-js":["/component---src-pages-index-js-decc5908d7606b1ebcc9.js"],"component---src-pages-search-js":["/component---src-pages-search-js-4140dcd6c0b17cbb677d.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-f9a7f3940ce358b5d109.js"],"component---src-templates-category-js":["/component---src-templates-category-js-5bfe119bd59960fd505e.js"]};/*]]>*/</script><script src="/polyfill-2d63daeed7f68b4f099c.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-f9a7f3940ce358b5d109.js" async=""></script><script src="/7a297f752dcfe258c0b0106d89edb3a916af916e-37098fdb13001ec95411.js" async=""></script><script src="/b1bda0e5b3305dd279ac60c39e10b0f82af56c10-30f26f77b6c7c05712d1.js" async=""></script><script src="/1bfc9850-409296e666dade882413.js" async=""></script><script src="/5e2a4920-da90abce4a08c86a094c.js" async=""></script><script src="/d7eeaac4-dcbe97e7a5aa158c9d08.js" async=""></script><script src="/app-f6ca4d5f718b892ec182.js" async=""></script><script src="/dc6a8720040df98778fe970bf6c000a41750d3ae-899cddfdf609eb8bc0c3.js" async=""></script><script src="/framework-b049b847da93b37c0f49.js" async=""></script><script src="/styles-f2c1808a00cfb3adf39e.js" async=""></script><script src="/webpack-runtime-a3cc835446b553ef5321.js" async=""></script></body></html>