{"componentChunkName":"component---src-templates-blog-post-js","path":"/research/generative-ml/","result":{"data":{"site":{"siteMetadata":{"author":"Imron Rosyadi","comment":{"utterances":""},"sponsor":{"buyMeACoffeeId":"irosyadi"}}},"markdownRemark":{"excerpt":"Generative Machine Learning GAN GAN The dataset was web-scraped for an original 20k samples, then a custom MRCNN model was trained for image segmentation and cropping before being fed into the 128 DC‚Ä¶","html":"<h1 id=\"generative-machine-learning-gan\" style=\"position:relative;\"><a href=\"#generative-machine-learning-gan\" aria-label=\"generative machine learning gan permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Machine Learning GAN</h1>\n<h2 id=\"gan\" style=\"position:relative;\"><a href=\"#gan\" aria-label=\"gan permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN</h2>\n<p>The dataset was web-scraped for an original 20k samples, then a custom MRCNN model was trained for image segmentation and cropping before being fed into the 128 DCGAN, trained on local hardware, 1660</p>\n<ul>\n<li><a href=\"https://github.com/w86763777/pytorch-gan-collections\">Collections of GANs : Pytorch implementation of unsupervised GANs.</a></li>\n</ul>\n<h2 id=\"generative-model-course\" style=\"position:relative;\"><a href=\"#generative-model-course\" aria-label=\"generative model course permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Model Course</h2>\n<ul>\n<li><a href=\"https://courses.cs.washington.edu/courses/cse599i/20au/\">CSE 599</a></li>\n<li><a href=\"https://deepgenerativemodels.github.io/notes/index.html\">deepgenerativemodels</a></li>\n</ul>\n<h2 id=\"gan-course\" style=\"position:relative;\"><a href=\"#gan-course\" aria-label=\"gan course permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN Course</h2>\n<ul>\n<li><a href=\"https://www.deeplearning.ai/program/deep-learning-specialization/\">Deep Learning Specialization | DeepLearning.AI</a></li>\n<li><a href=\"https://college.berklee.edu/courses/mtec-345\">Machine Learning for Musicians | Berklee</a></li>\n<li><a href=\"https://www.kadenze.com/courses/machine-learning-for-music-information-retrieval/info\">MUSIC DATA MINING - a Music Information Retrieval (MIR) Online Course at Kadenze</a></li>\n<li><a href=\"https://www.kadenze.com/courses/foundations-of-arts-and-entertainment-technologies-i/info\">Arts and Entertainment Technology - Online Course | Kadenze</a></li>\n<li><a href=\"https://www.kadenze.com/courses/generative-art-and-computational-creativity/info\">Introduction to Generative Arts and Computational Creativity - an Online Course at Kadenze</a></li>\n<li><a href=\"https://instituteofcoding.org/courses/course/ual-apply-creative-machine-learning/\">UAL - Apply Creative Machine Learning - Institute of CodingInstitute of Coding</a></li>\n<li><a href=\"https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info\">Machine Learning for Musicians and Artists - an Online Machine Art Course at Kadenze</a></li>\n<li><a href=\"https://www.youtube.com/user/bustbright/playlists\">Artificial Images - YouTube</a></li>\n</ul>\n<h2 id=\"generative-patterns\" style=\"position:relative;\"><a href=\"#generative-patterns\" aria-label=\"generative patterns permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Patterns</h2>\n<ul>\n<li>\n<p><a href=\"https://kwj2104.github.io/2018/cppngan/\">Generative Art with Compositional Pattern Producing Networks and GANs - K</a></p>\n<ul>\n<li><a href=\"https://kwj2104.github.io/2018/cppngan-2/\">Generative Art with CPPN-GANs Part II - K</a></li>\n<li><a href=\"https://github.com/kwj2104/CPPN-WGAN\">kwj2104/CPPN-WGAN: Generative Art Experiments</a></li>\n<li><a href=\"https://github.com/marcin7Cd/variant-of-CPPN-GAN\">marcin7Cd/variant-of-CPPN-GAN: based on https://github.com/kwj2104/CPPN-WGAN, but on chineses fonts and improved architecture</a></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/mxgmn/WaveFunctionCollapse\">mxgmn/WaveFunctionCollapse: Bitmap &#x26; tilemap generation from a single example with the help of ideas from quantum mechanics</a></li>\n<li>\n<p><a href=\"https://towardsdatascience.com/making-deep-neural-networks-paint-to-understand-how-they-work-4be0901582ee\">Making deep neural networks paint to understand how they work - by Paras Chopra - Towards Data Science</a></p>\n<ul>\n<li><a href=\"https://github.com/paraschopra/abstract-art-neural-network\">paraschopra/abstract-art-neural-network: Generating abstract art through neural networks in PyTorch</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"gan-1\" style=\"position:relative;\"><a href=\"#gan-1\" aria-label=\"gan 1 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN</h2>\n<ul>\n<li><a href=\"https://github.com/NVlabs/stylegan3\">NVlabs/stylegan3: Official PyTorch implementation of StyleGAN3</a></li>\n</ul>\n<h2 id=\"style-gan\" style=\"position:relative;\"><a href=\"#style-gan\" aria-label=\"style gan permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Style GAN</h2>\n<ul>\n<li><a href=\"https://www.gwern.net/Faces?ref=mlnews#examples\">Making Anime Faces With StyleGAN ¬∑ Gwern.net</a></li>\n<li><a href=\"https://github.com/cedricoeldorf/ConditionalStyleGAN\">cedricoeldorf/ConditionalStyleGAN: Conditional implementation for NVIDIA's StyleGAN architecture</a></li>\n<li>\n<p><a href=\"https://github.com/NVlabs/stylegan\">NVlabs/stylegan: StyleGAN - Official TensorFlow Implementation</a></p>\n<ul>\n<li><a href=\"https://old.reddit.com/r/computervision/comments/bfcnbj/p_stylegan_on_oxford_visual_geometry_group/\">P StyleGAN on Oxford Visual Geometry Group Flowers 102 Dataset üíêüåªüå∑ü•Äüå∫üåπüå∏üåº : computervision</a></li>\n<li><a href=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/\">Visual Geometry Group - University of Oxford</a></li>\n</ul>\n</li>\n<li><a href=\"https://medium.com/gradientcrescent/this-president-does-not-exist-generating-artistic-portraits-of-donald-trump-using-stylegan-a97a17902dd4\">ThisPresidentDoesNotExist: Generating Artistic Presidential Portraits using Style-based Adversarial Networks and Transfer Learning: Theory and Implementation in Tensorflow - by Adrian Yijie Xu - GradientCrescent - Medium</a></li>\n<li><a href=\"https://github.com/colinrsmall/ehm_faces\">colinrsmall/ehm_faces</a></li>\n<li><a href=\"https://nvlabs.github.io/stylegan2/versions.html\">StyleGAN versions</a></li>\n<li><a href=\"https://github.com/t04glovern/stylegan-pokemon\">t04glovern/stylegan-pokemon: Generating Pokemon cards using a mixture of StyleGAN and RNN to create beautiful &#x26; vibrant cards ready for battle!</a></li>\n<li><a href=\"https://arxiv.org/abs/2011.05552\">2011.05552End-to-End Chinese Landscape Painting Creation Using Generative Adversarial Networks</a></li>\n<li><a href=\"https://arxiv.org/abs/1812.04948\">1812.04948 A Style-Based Generator Architecture for Generative Adversarial Networks</a></li>\n</ul>\n<h3 id=\"this-thing-does-not-exist\" style=\"position:relative;\"><a href=\"#this-thing-does-not-exist\" aria-label=\"this thing does not exist permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>This Thing Does Not Exist</h3>\n<ul>\n<li><a href=\"https://thiseyedoesnotexist.com/story/\">This eye does not exist</a></li>\n<li><a href=\"https://thisvesseldoesnotexist.com/#/\">This vessel does not exist.</a></li>\n<li><a href=\"https://github.com/EvgenyKashin/ganarts\">EvgenyKashin/ganarts: This T-shirt does not exist</a></li>\n<li><a href=\"http://thesecatsdonotexist.com/\">thesecatsdonotexist.com</a></li>\n<li><a href=\"https://thisrentaldoesnotexist.com/\">Finca Es Corm√≥ di Friendly district - Guest suites for Rent</a></li>\n<li><a href=\"https://thispersondoesnotexist.com/\">This Person Does Not Exist</a></li>\n<li><a href=\"https://www.thismusicvideodoesnotexist.com/\">This Music Video Does Not Exist</a></li>\n<li><a href=\"https://www.hicetnunc.xyz/AIREGAN\">hic et nunc - hic et nunc</a></li>\n<li><a href=\"https://www.aire-gan.com/\">https://www.aire-gan.com</a></li>\n<li><a href=\"https://thissneakerdoesnotexist.com/\">This sneaker does not exist</a></li>\n<li><a href=\"https://imgflip.com/ai-meme\">This Meme Does Not Exist - Imgflip</a></li>\n<li><a href=\"https://thisxdoesnotexist.com/\">This x does not exist</a></li>\n<li><a href=\"https://thisbeachdoesnotexist.com/\">This beach does not exist</a></li>\n<li><a href=\"https://www.thischemicaldoesnotexist.com/\">This Chemical Does Not Exist</a></li>\n<li><a href=\"http://www.thesetoonsdonotexist.com/\">TheseToonsDoNotExist</a></li>\n<li><a href=\"https://www.thisworddoesnotexist.com/\">This Word Does Not Exist</a></li>\n<li><a href=\"https://www.thiswaifudoesnotexist.net/\">This Waifu Does Not Exist v3.5 (TWDNEv3.5) - Gwern</a></li>\n</ul>\n<h2 id=\"gan-image-superresolution\" style=\"position:relative;\"><a href=\"#gan-image-superresolution\" aria-label=\"gan image superresolution permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN Image Superresolution</h2>\n<ul>\n<li><a href=\"https://github.com/n00mkrad/cupscale\">Cupscale</a></li>\n<li><a href=\"https://github.com/xinntao/Real-ESRGAN\">Real-ESRGAN</a></li>\n</ul>\n<h2 id=\"gan-2\" style=\"position:relative;\"><a href=\"#gan-2\" aria-label=\"gan 2 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GAN</h2>\n<ul>\n<li><a href=\"https://www.gwern.net/Faces\">Making Anime Faces With StyleGAN ¬∑ Gwern.net</a></li>\n</ul>\n<h2 id=\"style-gan-1\" style=\"position:relative;\"><a href=\"#style-gan-1\" aria-label=\"style gan 1 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Style-GAN</h2>\n<ul>\n<li><a href=\"https://github.com/junyanz/CycleGAN\">junyanz/CycleGAN: Software that can generate photos from paintings, turn horses into zebras, perform style transfer, and more.</a></li>\n<li><a href=\"https://github.com/kaonashi-tyc/zi2zi\">kaonashi-tyc/zi2zi: Learning Chinese Character style with conditional GAN</a></li>\n<li><a href=\"https://github.com/rosinality/style-based-gan-pytorch\">rosinality/style-based-gan-pytorch: Implementation A Style-Based Generator Architecture for Generative Adversarial Networks in PyTorch</a></li>\n<li><a href=\"https://github.com/taki0112/StyleGAN-Tensorflow\">taki0112/StyleGAN-Tensorflow: Simple &#x26; Intuitive Tensorflow implementation of StyleGAN (CVPR 2019 Oral)</a></li>\n<li><a href=\"https://github.com/mtobeiyf/sketch-to-art\">mtobeiyf/sketch-to-art: üñº Create artwork from your casual sketch with GAN and style transfer</a></li>\n<li><a href=\"https://github.com/taki0112/UGATIT\">taki0112/UGATIT: Official Tensorflow implementation of U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation (ICLR 2020)</a></li>\n<li><a href=\"https://github.com/zeka-io/selfie-to-anime\">zeka-io/selfie-to-anime</a></li>\n<li><a href=\"https://github.com/boistud/StyleArtGan\">boistud/StyleArtGan</a></li>\n<li><a href=\"https://github.com/heavenstobetsy/ArtGenerationwithStyleGan\">heavenstobetsy/ArtGenerationwithStyleGan: Fauvist art generation using StyleGAN</a></li>\n<li><a href=\"https://github.com/zhenxuan00/triple-gan\">zhenxuan00/triple-gan: See Triple-GAN-V2 in PyTorch: https://github.com/taufikxu/Triple-GAN</a></li>\n<li><a href=\"https://github.com/Mawiszus/TOAD-GAN\">Mawiszus/TOAD-GAN: Official repository for \"TOAD-GAN: Coherent Style Level Generation from a Single Example\" by Maren Awiszus, Frederik Schubert and Bodo Rosenhahn.</a></li>\n<li><a href=\"https://github.com/schrum2/GameGAN\">schrum2/GameGAN: Interactive GAN evolution of Mario and Zelda levels.</a></li>\n<li><a href=\"https://github.com/changebo/HCCG-CycleGAN\">changebo/HCCG-CycleGAN: Handwritten Chinese Characters Generation</a></li>\n</ul>\n<h2 id=\"research\" style=\"position:relative;\"><a href=\"#research\" aria-label=\"research permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Research</h2>\n<ul>\n<li><a href=\"https://www.sciencedirect.com/science/article/pii/S1474034621001336?via%3Dihub\">An enhanced 3D model and generative adversarial network for automated generation of horizontal building mask images and cloudless aerial photographs - ScienceDirect</a></li>\n</ul>\n<h2 id=\"image-generator\" style=\"position:relative;\"><a href=\"#image-generator\" aria-label=\"image generator permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Generator</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2108.02708\">Object Wake-up: 3-D Object Reconstruction, Animation, and in-situ Rendering from a Single Image</a></li>\n<li><a href=\"https://creator.nightcafe.studio/text-to-image-art\">ü§ñ üñº AI Text-To-Image Art Generator - NightCafe Creator</a></li>\n<li><a href=\"https://makeai.art/\">makeai.art - create AI-generated from just a description</a></li>\n<li><a href=\"https://neuralblender.com/\">NeuralBlender.com</a></li>\n<li><a href=\"https://colab.research.google.com/drive/1Foi0mCSE6NrW9oI3Fhni7158Krz4ZXdH\">Google Colab</a></li>\n<li><a href=\"https://huggingface.co/spaces/flax-community/dalle-mini\">DALL¬∑E mini - a Hugging Face Space by flax-community</a></li>\n<li><a href=\"https://docs.google.com/document/d/1N57oAF7j9SuHcy5zg2VZWhttLwR_uEldeMr-VKzlVIQ/edit\">Generative Tools - Google Docs</a></li>\n</ul>\n<h2 id=\"research-1\" style=\"position:relative;\"><a href=\"#research-1\" aria-label=\"research 1 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Research</h2>\n<ul>\n<li><a href=\"https://realless.glitch.me/\">Realless</a> Generative webs with blinking eyes</li>\n</ul>\n<h2 id=\"generative-art\" style=\"position:relative;\"><a href=\"#generative-art\" aria-label=\"generative art permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Art</h2>\n<ul>\n<li><a href=\"https://contextfreeart.org/\">Context Free Art</a></li>\n<li><a href=\"http://canonical.org/~kragen/sw/dev3/skitch\">Skitching in HTML</a></li>\n<li><a href=\"http://xosh.org/Stochastic-L-System/\">xosh.org/Stochastic-L-System/</a></li>\n<li><a href=\"https://lsystems.raphaelpour.de/\">L-Systems</a></li>\n<li><a href=\"https://tool.graphics/mondrian\">Tool.Graphics | Mondrian</a></li>\n<li><a href=\"https://tool.graphics/suprematism\">Tool.Graphics | Suprematism</a></li>\n<li><a href=\"https://doersino.github.io/uji/\">UJI Generative Arts</a></li>\n<li><a href=\"https://opinionatedguide.github.io/#/Design/d5-gen\">Generative arts</a></li>\n<li><a href=\"https://github.com/mxgmn/WaveFunctionCollapse\">mxgmn/WaveFunctionCollapse: Bitmap &#x26; tilemap generation from a single example with the help of ideas from quantum mechanics</a></li>\n</ul>\n<h2 id=\"music-generation\" style=\"position:relative;\"><a href=\"#music-generation\" aria-label=\"music generation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Music Generation</h2>\n<ul>\n<li><a href=\"https://deepjazz.io/\">deepjazz: deep learning for jazz</a> <a href=\"https://github.com/jisungk/deepjazz\">jisungk/deepjazz: Deep learning driven jazz generation using Keras &#x26; Theano!</a></li>\n<li>\n<p><a href=\"https://github.com/KarthikNayak/DeepRock\">KarthikNayak/DeepRock: Rock Music using Deep Learning</a></p>\n<ul>\n<li><a href=\"https://nayak.io/posts/deeprock/\">Deeprock: LSTM based Rock Guitar Generator ¬∑ Karthik Nayak</a></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/Skuldur/Classical-Piano-Composer\">Skuldur/Classical-Piano-Composer</a></li>\n<li><a href=\"https://github.com/salu133445/musegan\">salu133445/musegan: An AI for Music Generation</a> <a href=\"https://www.reddit.com/r/deeplearning/comments/b29578/deep_learning_music_music_generation_using_gan/\">reddit</a></li>\n<li><a href=\"https://magenta.tensorflow.org/music-transformer\">Music Transformer: Generating Music with Long-Term Structure</a></li>\n<li><a href=\"https://www.reddit.com/r/MachineLearning/comments/kqoxo3/generative_deep_learning_for_virtuosic_classical/\">Generative Deep Learning for Virtuosic Classical Music: Generative Adversarial Networks as Renowned Composers : MachineLearning</a></li>\n<li><a href=\"https://magenta.tensorflow.org/performance-rnn-browser\">Real-time Performance RNN in the Browser</a></li>\n<li>\n<p><a href=\"https://sites.google.com/site/anayebihomepage/cs224dfinalproject\">GRUV: Algorithmic Music Generation using Recurrent Neural Networks - Aran Nayebi</a></p>\n<ul>\n<li><a href=\"https://github.com/MattVitelli/GRUV\">MattVitelli/GRUV: GRUV is a Python project for algorithmic music generation.</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"colorization\" style=\"position:relative;\"><a href=\"#colorization\" aria-label=\"colorization permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Colorization</h2>\n<ul>\n<li>\n<p>Pix2pix vs CycleGAN</p>\n<ul>\n<li>Cycle-GAN can work in an 'unpaired' manner and various architectural differences. Unpaired image translation is much harder, as you demand the model to learn objects of different shapes, size, angle, texture, location in different scenes and settings on top of the actual task (coloring in this case). Requires more data and you don't have fine control on the learning. Formulating the coloring problem as a paired task makes more sense as you simply decrease the complexity of the problem without increasing data collection/annotation work.</li>\n<li>The whole point about using CycleGAN is that it can learn in unpaired situations. And it works well in the context of style transfer tasks where the changes are really bold and less nuanced. But, in the context of image colorization, the changes are really subtle and also there are way more options to choose colors than changing a horse to zebra. The other thing is that learning to change a colored image to black and white is much easier for the model than learning to colorize it which can lead to a bad learning procedure.</li>\n<li>The most prominent differences is that CycleGAN helps when you have unpaired images and you want to go from one class to the other (Horse to Zebra for example) but in the Pix2Pix paper, the images that you get after the inference, are the input images but with some new features (black&#x26;white to colorized or day time to night time of a scene). In pix2pix, a conditional GAN (one generator and one discriminator) is used with some supervision from L1 loss. In CycleGAN, you need two generators and two discriminators to do the task: one pair for going from class A to B and one pair for going from class B to A. Also you need Cycle Consistency Loss to make sure that the models learn to undo the changes they make.</li>\n</ul>\n</li>\n<li>pix2pixhd is pix2pix in higher resolution</li>\n<li>\n<p>pix2pix tutorial and example:</p>\n<ul>\n<li><a href=\"https://github.com/moein-shariatnia/Deep-Learning/tree/main/Image%20Colorization%20Tutorial\">Github</a></li>\n<li><a href=\"https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8?source=friends_link&#x26;sk=e9d275985a6e00ada31e48ddc903fc9d\">Tutorial</a> </li>\n<li><a href=\"https://colab.research.google.com/github/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/Image%20Colorization%20with%20U-Net%20and%20GAN%20Tutorial.ipynb\">Jupyter in Colab</a></li>\n</ul>\n</li>\n</ul>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/research/generative-ml/#generative-machine-learning-gan\">Generative Machine Learning GAN</a></p>\n<ul>\n<li><a href=\"/research/generative-ml/#gan\">GAN</a></li>\n<li><a href=\"/research/generative-ml/#generative-model-course\">Generative Model Course</a></li>\n<li><a href=\"/research/generative-ml/#gan-course\">GAN Course</a></li>\n<li><a href=\"/research/generative-ml/#generative-patterns\">Generative Patterns</a></li>\n<li><a href=\"/research/generative-ml/#gan-1\">GAN</a></li>\n<li>\n<p><a href=\"/research/generative-ml/#style-gan\">Style GAN</a></p>\n<ul>\n<li><a href=\"/research/generative-ml/#this-thing-does-not-exist\">This Thing Does Not Exist</a></li>\n</ul>\n</li>\n<li><a href=\"/research/generative-ml/#gan-image-superresolution\">GAN Image Superresolution</a></li>\n<li><a href=\"/research/generative-ml/#gan-2\">GAN</a></li>\n<li><a href=\"/research/generative-ml/#style-gan-1\">Style-GAN</a></li>\n<li><a href=\"/research/generative-ml/#research\">Research</a></li>\n<li><a href=\"/research/generative-ml/#image-generator\">Image Generator</a></li>\n<li><a href=\"/research/generative-ml/#research-1\">Research</a></li>\n<li><a href=\"/research/generative-ml/#generative-art\">Generative Art</a></li>\n<li><a href=\"/research/generative-ml/#music-generation\">Music Generation</a></li>\n<li><a href=\"/research/generative-ml/#colorization\">Colorization</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"date":"Wed, Nov 17, 2021","title":"Generative Machine Learning GAN","tags":["generative","machine","learning","GAN"]}}},"pageContext":{"slug":"/research/generative-ml/","previous":{"fields":{"slug":"/app/video-editor/"},"frontmatter":{"title":"Awesome List of Video Editors"}},"next":{"fields":{"slug":"/note/tech-reading/"},"frontmatter":{"title":"Interesting Technology Articles"}}}},"staticQueryHashes":["1081905842","63159454"]}