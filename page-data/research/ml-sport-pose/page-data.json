{"componentChunkName":"component---src-templates-blog-post-js","path":"/research/ml-sport-pose/","result":{"data":{"site":{"siteMetadata":{"author":"Imron Rosyadi","comment":{"utterances":""},"sponsor":{"buyMeACoffeeId":"irosyadi"}}},"markdownRemark":{"excerpt":"Machine Learning for Sport Pose Analysis Pose Estimation Pose Estimation in Jetson Device Blog Sport Pose Analysis Badminton Pose Analysis Action Dataset (Tennis and Badminton) Ref-1 Ref-2 Ref-3 Ref-â€¦","html":"<h1 id=\"machine-learning-for-sport-pose-analysis\" style=\"position:relative;\"><a href=\"#machine-learning-for-sport-pose-analysis\" aria-label=\"machine learning for sport pose analysis permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine Learning for Sport Pose Analysis</h1>\n<h2 id=\"pose-estimation\" style=\"position:relative;\"><a href=\"#pose-estimation\" aria-label=\"pose estimation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pose Estimation</h2>\n<ul>\n<li><a href=\"https://github.com/NVIDIA-AI-IOT/deepstream_pose_estimation\">Pose Estimation in Jetson Device</a> <a href=\"https://developer.nvidia.com/blog/creating-a-human-pose-estimation-application-with-deepstream-sdk/\">Blog</a></li>\n</ul>\n<h2 id=\"sport-pose-analysis\" style=\"position:relative;\"><a href=\"#sport-pose-analysis\" aria-label=\"sport pose analysis permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sport Pose Analysis</h2>\n<ul>\n<li><a href=\"https://github.com/deepaktalwardt/badminton-pose-analysis\">Badminton Pose Analysis</a></li>\n<li><a href=\"https://www.cvssp.org/acasva/Downloads\">Action Dataset (Tennis and Badminton)</a></li>\n<li><a href=\"https://www.researchgate.net/publication/316477606_Computer_vision_for_sports_Current_applications_and_research_topics\">Ref-1</a></li>\n<li><a href=\"https://www.researchgate.net/publication/332378399_Position_Detection_for_Badminton_Tactical_Analysis_based_on_Multi-person_Pose_Estimation\">Ref-2</a></li>\n<li><a href=\"https://ieeexplore.ieee.org/document/8686917\">Ref-3</a></li>\n<li><a href=\"https://www.cs.ccu.edu.tw/~wtchu/papers/2017ICMR-chu.pdf\">Ref-4</a></li>\n<li><a href=\"https://dl.acm.org/doi/pdf/10.1145/3375959.3375981?download=true\">Ref-5</a></li>\n<li><a href=\"https://www.groundai.com/project/followmeup-sports-new-benchmark-for-2d-human-keypoint-recognition/1#bib.bib16\">Ref-6</a></li>\n<li><a href=\"https://deepai.org/publication/coachai-a-project-for-microscopic-badminton-match-data-collection-and-tactical-analysis\">Ref-7</a></li>\n<li><a href=\"https://ieeexplore.ieee.org/document/8686917\">Ref-8</a></li>\n</ul>\n<h2 id=\"pose-estimation-1\" style=\"position:relative;\"><a href=\"#pose-estimation-1\" aria-label=\"pose estimation 1 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pose Estimation</h2>\n<h3 id=\"methods\" style=\"position:relative;\"><a href=\"#methods\" aria-label=\"methods permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Methods</h3>\n<ul>\n<li>HRNet</li>\n<li>OpenPose</li>\n<li>HigherHRNet</li>\n<li>Smiple Baselines</li>\n<li>Alphapose</li>\n<li>Densepose</li>\n<li>Personlab</li>\n</ul>\n<h3 id=\"datasets\" style=\"position:relative;\"><a href=\"#datasets\" aria-label=\"datasets permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Datasets</h3>\n<ul>\n<li>\n<p><a href=\"https://cocodataset.org/#home\">COCO</a> (Common Objects in Context)</p>\n<ul>\n<li>Benchmark; Images from Flickr</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://human-pose.mpi-inf.mpg.de/\">MPII Human Pose</a> (body_25)</p>\n<ul>\n<li>25k images, 40k people, 401 human activities, extracted from YouTube videos</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://sam.johnson.io/research/lsp.html\">Leeds Sports Pose</a></p>\n<ul>\n<li>2k images of mostly Sports from Flickr</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://human-pose.mpi-inf.mpg.de/\">Frames Labeled in Cinema</a> (FLIC)</p>\n<ul>\n<li>5003 Images from movies labeled by Amazon Mechanical Turk</li>\n</ul>\n</li>\n<li><a href=\"https://jonathantompson.github.io/flic_plus.htm\">FLIC Plus</a> by <a href=\"https://jonathantompson.github.io/\">Jon Tompson</a></li>\n<li>\n<p><a href=\"https://vision.imar.ro/human3.6m/description.php\">Human3.6M</a></p>\n<ul>\n<li>3D Single Person</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://humaneva.is.tue.mpg.de/\">HumanEva</a></p>\n<ul>\n<li>7 videos with 3D body poses, 4 subjects, 6 common actions</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://www.di.ens.fr/willow/research/surreal/data/\">SURREAL</a></p>\n<ul>\n<li>6m frames of Synthetic Humans</li>\n</ul>\n</li>\n<li><a href=\"https://domedb.perception.cs.cmu.edu/\">Panoptic</a></li>\n<li><a href=\"https://github.com/chonyy/AI-basketball-analysis\">Basketball Pose Analysis</a></li>\n</ul>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/research/ml-sport-pose/#machine-learning-for-sport-pose-analysis\">Machine Learning for Sport Pose Analysis</a></p>\n<ul>\n<li><a href=\"/research/ml-sport-pose/#pose-estimation\">Pose Estimation</a></li>\n<li><a href=\"/research/ml-sport-pose/#sport-pose-analysis\">Sport Pose Analysis</a></li>\n<li>\n<p><a href=\"/research/ml-sport-pose/#pose-estimation-1\">Pose Estimation</a></p>\n<ul>\n<li><a href=\"/research/ml-sport-pose/#methods\">Methods</a></li>\n<li><a href=\"/research/ml-sport-pose/#datasets\">Datasets</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"date":"Sun, Oct 11, 2020","title":"Machine Learning for Sport Pose Analysis","tags":["machine learning","sport","pose estimation"]}}},"pageContext":{"slug":"/research/ml-sport-pose/","previous":{"fields":{"slug":"/research/ml-satellite-image/"},"frontmatter":{"title":"Machine Learning for Satellite Images"}},"next":{"fields":{"slug":"/app/hosted-open-source-service/"},"frontmatter":{"title":"Hosted Open Source Services"}}}},"staticQueryHashes":["1081905842","63159454"]}