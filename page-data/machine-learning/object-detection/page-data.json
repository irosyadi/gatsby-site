{"componentChunkName":"component---src-templates-blog-post-js","path":"/machine-learning/object-detection/","result":{"data":{"site":{"siteMetadata":{"author":"Imron Rosyadi","comment":{"utterances":""},"sponsor":{"buyMeACoffeeId":"irosyadi"}}},"markdownRemark":{"excerpt":"Object Detection Object Detection Object detection in an hour - Stray Robots Blog Object Detection and Segmentation facebookresearch/detectron2: Detectron2 is FAIR's next-generation platform for obje…","html":"<h1 id=\"object-detection\" style=\"position:relative;\"><a href=\"#object-detection\" aria-label=\"object detection permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Detection</h1>\n<h2 id=\"object-detection-1\" style=\"position:relative;\"><a href=\"#object-detection-1\" aria-label=\"object detection 1 permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Detection</h2>\n<ul>\n<li><a href=\"https://www.strayrobots.io/blog/object-detection-in-an-hour\">Object detection in an hour - Stray Robots Blog</a></li>\n</ul>\n<h2 id=\"object-detection-and-segmentation\" style=\"position:relative;\"><a href=\"#object-detection-and-segmentation\" aria-label=\"object detection and segmentation permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Detection and Segmentation</h2>\n<ul>\n<li><a href=\"https://github.com/facebookresearch/detectron2\">facebookresearch/detectron2: Detectron2 is FAIR's next-generation platform for object detection and segmentation.</a></li>\n<li><a href=\"https://segments.ai/blog/speed-up-image-segmentation-with-model-assisted-labeling\">Speed up your image segmentation workflow with model-assisted labeling - Segments</a></li>\n<li><a href=\"https://keras.io/examples/vision/oxford_pets_image_segmentation/\">Image segmentation with a U-Net-like architecture</a></li>\n</ul>\n<h2 id=\"in-browser-pose-identification\" style=\"position:relative;\"><a href=\"#in-browser-pose-identification\" aria-label=\"in browser pose identification permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>In-Browser Pose Identification</h2>\n<ul>\n<li>\n<p><a href=\"https://handsfree.js.org/\">Handsfree.js</a></p>\n<ul>\n<li><a href=\"https://github.com/MIDIBlocks/handsfree\">MIDIBlocks/handsfree: Integrate face, hand, and/or pose tracking to web</a></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/jeeliz/jeelizWeboji\">jeeliz/jeelizWeboji: JavaScript/WebGL real-time face tracking and expression detection library</a></li>\n</ul>\n<h2 id=\"rooftop-detection-machine-learning\" style=\"position:relative;\"><a href=\"#rooftop-detection-machine-learning\" aria-label=\"rooftop detection machine learning permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Rooftop Detection Machine Learning</h2>\n<ul>\n<li><a href=\"https://link.springer.com/article/10.1023/A:1025623527461\">Improved Rooftop Detection in Aerial Images with Machine Learning - SpringerLink</a></li>\n<li><a href=\"https://www.hindawi.com/journals/isrn/2013/819768/\">Novel Approach for Rooftop Detection Using Support Vector Machine</a></li>\n<li><a href=\"https://fractalytics.io/rooftop-detection-with-keras-tensorflow\">Deep-learning: Rooftop type detection with Keras and TensorFlow–fractalytics</a></li>\n<li><a href=\"https://towardsdatascience.com/using-image-segmentation-to-identify-rooftops-in-low-resolution-satellite-images-c791975d91cc\">Increasing Solar adoption in the developing world through Machine Learning image segmentation - by Rudradeb Mitra - Towards Data Science</a></li>\n</ul>\n<h2 id=\"hand-detection-and-hand-tracking\" style=\"position:relative;\"><a href=\"#hand-detection-and-hand-tracking\" aria-label=\"hand detection and hand tracking permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hand Detection and Hand Tracking</h2>\n<ul>\n<li><a href=\"https://github.com/victordibia/handtrack.js\">victordibia/handtrack.js: A library for prototyping realtime hand detection (bounding box), directly in the browser.</a></li>\n<li><a href=\"https://github.com/tensorflow/tfjs-models/tree/master/handpose\">tfjs-models/handpose at master · tensorflow/tfjs-models</a></li>\n<li><a href=\"https://handtracking.io/\">handtracking.io</a></li>\n<li><a href=\"https://www.microsoft.com/en-us/research/publication/robust-computer-vision-based-detection-pinching-one-two-handed-gesture-input/\">Robust Computer Vision-Based Detection of Pinching for One and Two-Handed Gesture Input - Microsoft Research</a></li>\n</ul>\n<h2 id=\"browser-based-facepose-identification\" style=\"position:relative;\"><a href=\"#browser-based-facepose-identification\" aria-label=\"browser based facepose identification permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Browser based Face/Pose Identification</h2>\n<ul>\n<li>\n<p><a href=\"https://handsfree.js.org/\">Handsfree.js</a></p>\n<ul>\n<li><a href=\"https://github.com/midiblocks/handsfree\">MIDIBlocks/handsfree: Quickly integrate face, hand, and/or pose tracking to your frontend projects in a snap ✨👌</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://github.com/esimov/pigo\">esimov/pigo: Fast face detection, pupil/eyes localization and facial landmark points detection library in pure Go.</a> Pupil Localization</p>\n<ul>\n<li><a href=\"https://www.visionworks.com/pd-measurement\">Pupillary Distance Measurement</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://drive.google.com/file/d/1bsWbokp9AklH2ANjCfmjqEzzxO1CNbMu/preview\">Mediapipe Iris</a> megabyte model to predict 2D eye, eyebrow and iris geometry from monocular video captured by a front-facing camera on a smartphone in real time.</p>\n<ul>\n<li><a href=\"https://github.com/google/mediapipe/tree/master/mediapipe/models\">mediapipe/mediapipe/models at master · google/mediapipe</a></li>\n<li><a href=\"https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html\">Google AI Blog: MediaPipe Iris: Real-time Iris Tracking &#x26; Depth Estimation</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"in-browser-object-detection\" style=\"position:relative;\"><a href=\"#in-browser-object-detection\" aria-label=\"in browser object detection permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>In-browser Object Detection</h2>\n<ul>\n<li><a href=\"https://dev.to/skalskip/in-browser-object-detection-using-yolo-and-tensorflow-js-4c9h\">In-Browser object detection using YOLO and TensorFlow.js - DEV Community 👩‍💻👨‍💻</a></li>\n<li><a href=\"https://codelabs.developers.google.com/codelabs/tensorflowjs-object-detection#0\">TensorFlow.js: Make a smart webcam in JavaScript with a pre-trained Machine Learning model</a></li>\n<li><a href=\"https://github.com/ModelDepot/tfjs-yolo-tiny\">ModelDepot/tfjs-yolo-tiny: In-Browser Object Detection using Tiny YOLO on Tensorflow.js</a></li>\n<li><a href=\"https://synthiam.com/Community/Questions/In-Browser-object-detection-using-YOLO-and-TensorFlow-js-19178\">In-Browser object detection using YOLO and TensorFlow.js - Questions - Community - Synthiam</a></li>\n<li>\n<p><a href=\"https://towardsdatascience.com/build-a-realtime-object-detection-web-app-in-30-minutes-7ad0cb2231fb\">Build a Realtime Object Detection Web App in 30 Minutes - by Erdem Isbilen - Towards Data Science</a></p>\n<ul>\n<li><a href=\"https://tfjs-objectdetection.firebaseapp.com/\">Demos</a></li>\n<li><a href=\"https://github.com/eisbilen/TFJS-ObjectDetection\">Github</a></li>\n</ul>\n</li>\n<li><a href=\"https://medium.com/swlh/build-custom-object-detection-web-application-using-tensorflow-js-d1664f96a18b\">Build Custom Object Detection Web Application Using TensorFlow.js - by Kosta Malsev - The Startup - Jan, 2021 - Medium</a></li>\n<li>\n<p><a href=\"https://nanonets.com/blog/object-detection-tensorflow-js/\">🤖 Object Detection using Tensorflow.js - Tutorial</a></p>\n<ul>\n<li><a href=\"https://nanonets.com/object-detection-with-tensorflowjs-demo/\">Demos</a></li>\n</ul>\n</li>\n<li><a href=\"https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html\">Custom object detection in the browser using TensorFlow.js—The TensorFlow Blog</a></li>\n</ul>\n<h2 id=\"yolo\" style=\"position:relative;\"><a href=\"#yolo\" aria-label=\"yolo permalink\" class=\"toc-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>YOLO</h2>\n<ul>\n<li><a href=\"https://www.kdnuggets.com/2018/09/object-detection-image-classification-yolo.html\">Object Detection and Image Classification with YOLO - KDnuggets</a> : YOLO is based on regression not classification</li>\n<li><a href=\"https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088\">Real-time Object Detection with YOLO, YOLOv2 and now YOLOv3 - by Jonathan Hui - Medium</a></li>\n<li><a href=\"https://github.com/WangMian-Maker/Flask\">WangMian-Maker/Flask</a></li>\n<li><a href=\"https://github.com/LeonLok/Multi-Camera-Live-Object-Tracking\">LeonLok/Multi-Camera-Live-Object-Tracking: Multi-camera live traffic and object counting with YOLO v4, Deep SORT, and Flask.</a></li>\n<li><a href=\"https://github.com/burningion/poor-mans-deep-learning-camera\">burningion/poor-mans-deep-learning-camera: Build a thin client deep learning camera with the Raspberry Pi, Flask, and YOLO</a></li>\n<li><a href=\"https://github.com/theAIGuysCode/Object-Detection-API\">theAIGuysCode/Object-Detection-API: Yolov3 Object Detection implemented as APIs, using TensorFlow and Flask</a></li>\n<li><a href=\"https://github.com/v-iashin/WebsiteYOLO\">v-iashin/WebsiteYOLO: The back-end for YOLOv3 object detector running online on my website</a></li>\n<li><a href=\"https://github.com/Zyjacya-In-love/Pedestrian-Detection-on-YOLOv3_Research-and-APP\">Zyjacya-In-love/Pedestrian-Detection-on-YOLOv3_Research-and-APP: 2020 Undergraduate Graduation Project in Jiangnan University ALL codes including Data-convert, keras-Train, model-Evaluate and Web-App</a></li>\n<li><a href=\"https://github.com/yankai364/Object-Detection-Flask-API\">yankai364/Object-Detection-Flask-API: A simple YOLOv3 object detection API in Python (using Flask).</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/10/easily-deploy-machine-learning-models-using-flask.html\">How to Easily Deploy Machine Learning Models Using Flask - KDnuggets</a> : show text results</li>\n<li><a href=\"https://www.datacamp.com/community/tutorials/machine-learning-models-api-python\">Turning Machine Learning Models into APIs - DataCamp</a></li>\n<li><a href=\"https://www.geeksforgeeks.org/deploy-machine-learning-model-using-flask/\">Deploy Machine Learning Model using Flask - GeeksforGeeks</a></li>\n<li><a href=\"https://www.kdnuggets.com/2019/12/excelr-deployment-machine-learning-flask.html\">Deployment of Machine learning models using Flask - KDnuggets</a></li>\n<li><a href=\"https://blog.cambridgespark.com/deploying-a-machine-learning-model-to-the-web-725688b851c7\">Tutorial: Deploying a machine learning model to the web - by Cambridge Spark - Cambridge Spark</a></li>\n<li><a href=\"https://www.toptal.com/python/python-machine-learning-flask-example\">Python Machine Learning and Predicting With Flask - Toptal</a></li>\n</ul>\n<p>There are a few different algorithms for object detection and they can be split into two groups:  </p>\n<ul>\n<li>Algorithms based on classification–they work in two stages. In the first step, we’re selecting from the image interesting regions. Then we’re classifying those regions using convolutional neural networks. This solution could be very slow because we have to run prediction for every selected region. Most known example of this type of algorithms is the Region-based convolutional neural network (RCNN) and their cousins Fast-RCNN and Faster-RCNN.</li>\n<li>Algorithms based on regression–instead of selecting interesting parts of an image, we’re predicting classes and bounding boxes for the whole image in one run of the algorithm. Most known example of this type of algorithms is YOLO (You only look once) commonly used for real-time object detection.</li>\n</ul>\n<p>YOLO metrics:</p>\n<ul>\n<li><a href=\"https://github.com/whynotw/YOLO_metric\">whynotw/YOLO_metric: Calculate mean Average Precision (mAP) and confusion matrix for object detection models. Bounding box information for groundtruth and prediction is YOLO training dataset format.</a></li>\n<li><a href=\"https://github.com/rafaelpadilla/review_object_detection_metrics\">rafaelpadilla/review<em>object</em>detection_metrics: Review on Object Detection Metrics: 14 object detection metrics including COCO's and PASCAL's metrics. Supporting different bounding box formats.</a></li>\n<li><a href=\"https://manalelaidouni.github.io/Evaluating-Object-Detection-Models-Guide-to-Performance-Metrics.html\">Evaluating Object Detection Models: Guide to Performance Metrics - Manal El Aidouni</a></li>\n</ul>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n</style>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/machine-learning/object-detection/#object-detection\">Object Detection</a></p>\n<ul>\n<li><a href=\"/machine-learning/object-detection/#object-detection-1\">Object Detection</a></li>\n<li><a href=\"/machine-learning/object-detection/#object-detection-and-segmentation\">Object Detection and Segmentation</a></li>\n<li><a href=\"/machine-learning/object-detection/#in-browser-pose-identification\">In-Browser Pose Identification</a></li>\n<li><a href=\"/machine-learning/object-detection/#rooftop-detection-machine-learning\">Rooftop Detection Machine Learning</a></li>\n<li><a href=\"/machine-learning/object-detection/#hand-detection-and-hand-tracking\">Hand Detection and Hand Tracking</a></li>\n<li><a href=\"/machine-learning/object-detection/#browser-based-facepose-identification\">Browser based Face/Pose Identification</a></li>\n<li><a href=\"/machine-learning/object-detection/#in-browser-object-detection\">In-browser Object Detection</a></li>\n<li><a href=\"/machine-learning/object-detection/#yolo\">YOLO</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"date":"Sat, Nov 21, 2020","title":"Object Detection","tags":["object detection","machine learning"]}}},"pageContext":{"slug":"/machine-learning/object-detection/","previous":{"fields":{"slug":"/machine-learning/face-expression-detection/"},"frontmatter":{"title":"Face Expression and Detection"}},"next":{"fields":{"slug":"/me/my-workflow/"},"frontmatter":{"title":"My Workflow"}}}},"staticQueryHashes":["1081905842","63159454"]}